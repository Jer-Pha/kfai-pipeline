{
    "id": 2435,
    "video_id": "A7-bMoLy0yQ",
    "show_name": "The GameOverGreggy Show",
    "hosts": [
        "Adam Setapen",
        "Colin Moriarty"
    ],
    "title": "Robotics, AI, and an Uncertain Future - The GameOverGreggy Show (Patreon Exclusive January 2017)",
    "description": "Colin's friend Adam -- an MIT-educated roboticist -- comes to the studio to talk about what he does for a living, to wax poetic about the future of robots and artificial intelligence, and to discuss why we should be both excited and horrified of what's to come.\n\nSubscribe! http://www.youtube.com/kindafunny?sub_confirmation=1\n\nSupport us and get the shows early here! http://www.patreon.com/kindafunny\n\nCheck out our store! http://www.kindafunny.com/store\n\nFollow us on Twitter!\nGreg - http://www.twitter.com/GameOverGreggy\nColin - http://www.twitter.com/NoTaxation\nTim - http://www.twitter.com/TimGettys\nNick - http://www.twitter.com/Nick_Scarpino\nKinda Funny - http://www.twitter.com/KindaFunnyVids\n\nEvery day Greg Miller, Colin Moriarty, Tim Gettys, and Nick Scarpino talk about the biggest stories in nerd culture.",
    "published_at": 1488117600,
    "duration": 3133,
    "transcript_chunks": [
        {
            "text": "greetings and salutations welcome to an exclusive episode a Patreon exclusive episode of The GameOverGreggy Show my name is K Warren already I'm here with my friend Adam Setapen who's a roboticist and I wanted to do this episode today inspired by a dinner Adam and I had a month or so ago uh because I bring up these nerdy topics on the game over greggy show which is our flagship podcast that you guys probably watch I'm sure that we've been doing for a few years and the idea of the show Adam in case You' never seen it and there's no reason why you should have is because we do basically four topics a week that are just random and unassociated with each other so it could be about uh someone's like I like to cook beef and then the other person's like I like looking at stars and then the other person's like you know and all that kind of stuff and I bring up often these nerdy AI and Robotics and kind of futurist kind of things on the show that no one cares about but me and then you and I",
            "start": 0.0
        },
        {
            "text": "Adam Setapen was like, \"You know, I'm into this nerdy AI and robotics stuff, and I always bring it up on the show, but no one really cares.\" He'd often talk about futurist things with me. Then he had dinner with his girlfriend's cousin, and we went to Urban Putt, which was a lot of fun. Adam said you and your friends from MIT were there, and I thought, \"Wow, that's a smart group of people.\" I was picking your brain, but I felt like I was being annoying, so I stopped. I told Adam, \"We should have you on the show soon to talk about what you do and what you know because you're really smart and I admire people who are smarter than me.\" He said he got his bachelor's degree in Texas, but went to MIT for grad school.",
            "start": 39.84
        },
        {
            "text": "much smarter than me and you're one of those people so um first of all you were you had your you got your bachelor's degree down in Texas but you went to MIT uh right for grad school is that that correct yes MIT, of course, is the Massachusetts Institute of Technology, one of the great schools in the world um very awesome you go there his girlfriend went to Harvard uh my my uh my my girlfriend's cousin so a pretty smart uh pretty smart group of people and uh you are in robotics which is fascinating to me and you understand AI and you understand all these things and you work very intimately with these kind of components here in Silicon Valley I'm just started a new job um and what what is your title at that job I am a senior robotics engineer for Mayfield Robotics um we make this little social robot named Kuri um and he's he kind of is a home helper think of Amazon Echo with wheels or Google Home with wheels um yeah that's awesome okay so when I found out that this is what you did I",
            "start": 80.04
        },
        {
            "text": "robot named Curie, um, and he's kind of is a home helper, think of Amazon Echo with wheels or Google Home with wheels, um, yeah that's awesome. Okay, so when I found out that this is what you did, I immediately uh my girlfriend Ain, who you guys know, I immediately started asking her questions about you because I'm like well said you want that my tea and he's in the robotics is so smart because I like to read about these things as I often say I've always been fascinated by science um and have a better than layman's understanding of certain things but I don't understand the math, I don't understand the theory, understand that kind of stuff. What I do is I read uh the books of people explaining this thing and I trust that the math and the science behind it is good because I certainly can't prove it right. You obviously have a much deeper and more thorough understanding of it but also are able to talk in a very eloquent way about the ramifications of AI, the ramifications of robotics in the",
            "start": 119.4
        },
        {
            "text": "it right, you obviously have a much deeper and more thorough understanding of it, but also are able to talk in a very eloquent way about the ramifications of AI, the ramifications of Robotics in the future, and futurism. Um, so I want to just... and as I told you beforehand, because this is my man Adam Setapen, and people that have been listening to me for years know, is I don't prepare notes for interviews, I don't prepare for interviews. I know what you do, and I know like uh what to where to start, and then we'll see where it goes. So I want to know... I want to start in a very specific place. Okay, are things about to get scary? I think things are not about to get scary, but the potential of them getting scary is very real, and is kind of festering in people's minds, and I think people are making more of the implications than they are today, in terms of Robotics, in terms of AI. I think things are getting a little more scary, but a robot takeover very unlikely. Okay, so where do we stand right now with AI, and with",
            "start": 155.8
        },
        {
            "text": "they are today in terms of Robotics in terms of AI I think things are getting a little more scary but a robot takeover very unlikely okay so where do we stand right now with AI and and with robotics generally what is the focus we hear a lot about driverless cars which seem to be a year two three years away from real fruition right a lot of companies seem to be investing a lot of money in them Google Apple a bunch of companies who knows like what's real what's not right um with that because it's a lot of very secretive kind of stuff we have AI becoming more not cian obviously but more useful I guess definitely um and we have these kinds of this kind of um this collaboration between the more robot like the engineering side robotics along with the the more programming side and software side AI that's becoming symbiotic with each other so where do we sit right now like what's going on in your field what's going on in your world what are you guys focusing on so a lot of the huge",
            "start": 202.0
        },
        {
            "text": "side AI that's becoming symbiotic with each other so where do we sit right now like what's going on in your field what's going on in your world what are you guys focusing on so a lot of the huge breakthroughs in AI um that Google and Facebook and places like that have been spearheading is because of the massive amounts of data that the internet is providing to them um so they have these algorithms that can be trained by all this data um and they can predict things very very well um but what is so difficult about robots is um and kind of the difference between AI maybe in a video game and AI on an actual robot is in robotics we we can break it down into three things sense plan and act um and sense is kind of sensing the world detecting everything around you having sensors that say that's a wall over there there's a person here in video games that's all done for you you have complete knowledge about the world um all the AI does um planning is kind of the AI part and that's gotten a lot",
            "start": 246.08
        },
        {
            "text": "Wall over there, there's a person here in video games that's all done for you. You have complete knowledge about the world. Um, all the AI does, um, planning is kind of the AI part and that's gotten a lot better recently because of all this data, and then acting in the physical world is another problem in video games it's very easy but in the physical world robots break down and they're weird events like a robot might go over a little lip and fall over and it can't get up and then it's done. Um, so that's kind of one of the big differences between AI as software and AI on robots is it takes a whole lot of engineers to keep something running in the physical world um but if it's an algorithm it can maintain itself. So that's why I think the potential of you know disaster with robots is low but with AI is you know it's it's higher. We'll say okay, so what is the practical application of what you guys are working on now? You're talking about you know this part this specific kind of housekeeping or",
            "start": 293.24
        },
        {
            "text": "AI is you know it's it's higher, we'll say okay. So, what is the practical application of what you guys are working on now? You're talking about this part, this specific kind of housekeeping or helping robot that you have. Things seem to be quite modest compared to what we see in sci-fi with the C-3POs or the droids in Star Wars or whatever that are like borderline sentient and can obviously do more uh I guess develop tasks. And then you see videos from guys like Boston Dynamics that are making like Metal Gear type robots that are a little more scary, right? What like where are we practically right now and then where do you think we're going to be in the next few years? Like how much of a quantum leap are we going to take? Because my assumption and I don't know if it's accurate or not is that we couldn't imagine having these smartphones. We we couldn't even imagine what a smartphone was 10 years ago, and then when they came out they slowly seeped into our minds and now they're",
            "start": 344.84
        },
        {
            "text": "or not is that we couldn't imagine having these smartphones, we we couldn't even imagine what a smartphone was 10 years ago, and then when they came out, they slowly seeped into our minds, and now they're they're part of not only the phone itself but everything we do, whether it's Uber, whether it's the way we communicate, and all that kind of stuff. Are we are we at a similar kind of Through the Looking Glass situation with this kind of stuff where we're getting to where it's going to advance quicker in terms of AI, yes, in terms of Robotics, um it's hard to say because it takes so much to maintain something that works in the physical world; a robot can't fix itself, um generally like when you see Boston Dynamics prototypes, that's one prototype that probably a team of 50 engineers has worked on for you know two to three years to make a demo or to make something that's useful, and in terms of what people want in their actual homes, when we look at robots, there's basically Roomba, the robotic vacuum cleaner.",
            "start": 382.04
        },
        {
            "text": "to 3 years to make a demo or to make something that's useful um and in terms of what people want in their actual homes when we look at robots there's basically Roomba the robotic vacuum cleaner and from the time that Roomba was released basically 10 years before that um the founder of iRobot was basically churning on this idea trying to create something reliable enough that could exist in a person's in a normal person's home clean it up decently well charge itself um and provide a functional task to the person now what's what's kind of in this gray area is what I focus on which is social robotics um robots that are meant to interact with people how those robots should interact with people and how we should design those robots to be appealing to people because we've seen that you know there's this kind of weird uncanny valley if you make a robot too humanoid looking it gets creepy looking um but if you make a robot simple um and emotive it can be very effective at conveying information",
            "start": 424.48
        },
        {
            "text": "this kind of weird uncanny valley if you make a robot too humanoid looking it gets creepy looking um but if you make a robot simple um and emotive it can be very effective at conveying information to a person okay so is it because I had one of those robots my old roommate a long time ago had one we was fascinated about come home every once in a while I'll be stuck somewhere dead like under the treadmill or whatever is that the first like practical robot that we had in our in our houses I mean is that like when you guys look back at at the robotics or AI or whatever is that really the first one of consequence yes yes I think it is and drones aren't really household robots but I think that's the second big consumer segment of Robotics that provides a function aerial video um and you can use that output in lots of different and novel ways um so that's more of an enabling robot than a Roomba um because you know you can take awesome footage of somebody surfing from a drone or you can use it to",
            "start": 479.12
        },
        {
            "text": "output in lots of different and novel ways um so that's more of an enabling robot than a Roomba um because you know you can take awesome footage of somebody surfing from a drone or you can use it to map you know a developing World um from above so it's more of a democratizing technology than a robotic vacuum cleaner and I think we'll see some very interesting Trends in drones in the next few years so with with the AI like kind of segment of it because we were talking a little bit about you know well something's very primitive like Siri or um what uh what Microsoft's doing with Cortana and then obviously like this Alexa **** that's going on with with Amazon right now you got like I'm not sure it's not your job but you have probably marketers or people that are more marketing Centric or more um in the weeds with like what people want in terms of like out of these robots is that is this what you guys are finding that people want something that's like you could just say like Alexa I need",
            "start": 528.0
        },
        {
            "text": "um in the weeds with like what people want in terms of like out of these robots, that's this what you guys are finding that people want something that's like you could just say like Alexa \"I need flowers because I burned something in my wife's house and she's going to be mad at me\" like is that really what people are finding or is there something like is that basically a stop gap until we can figure out something more novel for today right in the home, people really want to use voice and speech as an interface to everything because you're safe, you don't know if I'm walking down the street and I say \"hey Siri order me something explicit\" and somebody hears me, that's weird, I might not actually want to use voice as an interface, I might just want to pull out my phone order it but in in the home in your car you're more comfortable so voice is a really natural interface to interact with your devices with your data stuff like that um so I think that voice is a great interface for",
            "start": 574.0
        },
        {
            "text": "the home in your car you're more comfortable so voice is a really natural interface to interact with your devices with your data stuff like that um so i think that voice is a great interface for robots but i don't think robots are necessarily ready to talk to people um because that changes the expectation of what the robot can do so much you know a cat or a dog responds to your voice you can train it to go over there you can it knows its name but it's not going to respond to you through voice so that's kind of what we're trying to do with robotics now is lower the expectations so people are willing to use these interfaces that are not nearly as futuristic or advanced as people are used to seeing in movies and tv interesting one of the major things you and i remember talking about during that you know we were we were drinking we were eating we were having a good time was well two things i remember specifically we were talking about the turing test which i'm fascinated by and we",
            "start": 616.32
        },
        {
            "text": "that you know we were we were drinking we were eating we were having a good time was well two things I remember specifically we were talking about the Turing Test which I'm fascinated by and we were also talking about um uh well the T-Test in specifically with we were talking about AI and all these kinds of ways that we've seen it play out in fiction and the expectations of that um in particular uh but the other thing we were talking about was uh Ray Kurzweil and Singularity and the idea that computers are you know when computer intelligence becomes or grows to a pace where it's GNA where they're going to outsmart humans or whatever on a presumably a permanent basis and that's kind of where I wanted to steer this because this is where things get kind of I don't want to say like dystopian but they could get dystopian but it's just interesting about where we're going with this one of the fascinating things you told me about uh the Turing Test and for people that don't know the Turing",
            "start": 666.64
        },
        {
            "text": "but they could get dystopian but it's just interesting about where we're going with this one of the fascinating things you told me about uh the Turing Test and for people that don't know Turing Test is when a computer well you can explain it's when a computer can out convince a person that it's real right is that yes so so basically Bally the classical Turing test is um there is a room that you can't see into and you write down something on a piece of paper and slide it under the door and then you get a piece of paper back and it's a response and you basically have a conversation it was either generated by a computer or a human and at the end of this the person is supposed to say I think this was a computer I think this was a human um and you an algorithm passes the Turing Test if it can fake out 50% of people um so if it can convince more than half of the people that it is a human then it's indistinguishable from a human so that's the classical Turing Test it's just with text",
            "start": 705.36
        },
        {
            "text": "can fake out 50% of people um so if it can convince more than half of the people that it is a human then it's indistinguishable from a human so that's the classical Turing test it's just with text um kind of a more modern Turing test is having a face-to-face conversation with a being and trying to figure out if that being is a robot or not right and you were saying that and this isn't surprising to me I guess but that we are imminently close to the former but very far away from the latter right that's what I would think I mean we are very very close um and in fact some people have claimed to have Sol have have beaten the Turing test basically with algorithms um but in terms of talking to a conversational robot we're not there at all okay and and that's just to be clear you did call it the screen door was that the term you use or is it like where like the the former would be called that I guess right where you can't like but is there not an intermediary step between talking to it",
            "start": 750.12
        },
        {
            "text": "screen door was that the term you use or is it like where like the the former would be called that I guess right where you can't like but is there not an intermediary step between talking to it but not like to hearing and communicating with it in some sort of verbal way but not seeing it is that something that's like kind of intermediate and could be passable before yeah absolutely and I I think it will be you know with with all this data going into Alexa uh Google home all these things they're capturing all that data and that's very useful to them um any anytime you say hey Alexa um blah blah blah it records what you say um and even though the computer voices are not very Advanced right now they're getting massive amounts of data of real people speaking and the voices are going to get much more emotive much more realistic um in the future and I think we'll start to see conversational interfaces that could pass the Turing test with speech you know you're just talking to an entity",
            "start": 803.56
        },
        {
            "text": "much more emotive much more realistic um in the future and I think we'll start to see conversational interfaces that could pass the Turing test with speech you know you're just talking to an entity and it might sound and act exactly like a but it could be an algorithm and this uncanny valley problem is the reason why according in addition to I guess the limits of Robotics as we know it now is the reason why I couldn't sit in a room like Ex Machina and talk to someone and be tricked I guess we're we're very far away from that you would assume we're like lifetimes away from that or it's hard to say um we AI and Robotics started in this you know 50s 60s 70s and they they said it would be solved in 10 years and they were very confident in that um and obviously we are not there yet um when you look at Androids which is a humanoid robot um that's trying to look like a human they look creepy there aren't that many of them that look natural when they speak you can tell there's something",
            "start": 852.84
        },
        {
            "text": "you look at Androids which is a humanoid robot um that's trying to look like a human they look creepy there aren't that many of them that look natural when they speak you can tell there's something different about them um I I don't think much about that is going to change in the next 20 years but I could be wrong right yeah because it goes back to this idea of the acceleration not only I guess Moore's law kind of stuff but the acceleration of we had these you know we had you know Mac and Lisa and all these things that really advanced to a 486 very quickly which really advanced to a Pentium processor even quicker which then advanced so I guess the idea but it seems to be a more aesthetic thing and a more and this is much more complicated than making a personal computer or making a phone so it's much more dynamic kind of thing so I understand why you guys could reach that you know as a lay person could reach that conclusion that it seems almost impossible well it's it's basically",
            "start": 903.88
        },
        {
            "text": "much more dynamic kind of thing so I understand why you guys could reach that conclusion that it seems almost impossible well it's basically you have to emulate everything about the brain and about the physical um magic that is a human being you know we are very special creatures with emotive faces that are very complicated and even building a face that can emote like a humans is a very difficult task not to mention having it infer emotions about the other person you know if I'm talking about that water bottle and I point at it you know what I'm talking about but grounding a robot in the physical world um linking words you say to objects in the physical world we're still a very long way from that so talk to me a little bit about you know I guess we'll get into the meat and potatoes now specifically about the advancements in AI and how they can be useful but also how they can be detrimental or scary and I'm not talking necessarily",
            "start": 954.36
        },
        {
            "text": "I guess we'll get into the meat and potatoes now specifically about the advancements in AI and how they can be useful but also how they can be detrimental or scary. And I'm not talking necessarily about Skynet, but it seems like smart people - whether it's Elon Musk, or Bill Gates, or these guys - are being like, \"Well, we need to have some sort of international congress about what we're doing with these particular computer components because and these artificial intelligence systems because we can make something that we can't control. Um, and it can have far-reaching consequences for us as a species. What is it that's scary about them, and how do we kind of harness this energy and usefulness? And isn't the inevitable conclusion not that they're going to become scary regardless because they're going to become so smart?\"",
            "start": 1005.0
        },
        {
            "text": "do we kinda harness this energy and usefulness, and is the inevitable conclusion not that they're going to become scary regardless because they're going to become so smart? isn't in other words, is there some sort of like ethical concern that we might not want to go down this road at all because we can't turn back? I mean yes very much so. But I think technology in general has kinda moved us farther away from other social creatures - you know, social media points our faces at a screen instead of at another person. And one of the things that got me really fascinated in robotics when I started with it was that you are interacting with a creature; it is in your physical world; it's in your space; um, you can look at it; you can see it move; it feels more social to me; it feels more real. I think we will create beings that are more capable than us eventually, and we have a responsibility to make them ethically. What is but what is this specific concern like? We have these dynamic kind of",
            "start": 1043.56
        },
        {
            "text": "we will create beings that are more capable than us eventually and we have a responsibility to make them ethically yes what is but what is this specific concern like we have these dynamic kind of science fiction solutions or these kinds of alternate futures of you know uh defense systems that run amok or um in Battlestar Galactica this group of enslaved robots that turns on everyone or you know whatever is the realistic fear like in other words why is it always so dire it seems so dire like sci-fi seems to mimic a lot of what we end up having in the future anyway like these people are these are salient points that seem to be things that come to fruition eventually so why is it our why is it the conclusion of smart people like yourself and smart people like Bill Gates, Elon Musk, and these guys that just invest lots of money in technology that the outcome is inevitably going to be nefarious I guess I should say because any technology can be used",
            "start": 1092.6
        },
        {
            "text": "Bill Gates, Elon Musk, and these guys who just invest lots of money in technology, the outcome of which is inevitably going to be nefarious, I guess. I should say because any technology can be used positively or negatively, and if we had robots that were perfectly ethical and there was someone very smart who could subvert that, then it's a huge issue. So, I think the fear is more in that if we don't have some way to control the ethics of a robot or to dictate what is acceptable behavior for a robot or not, um, that people will start doing that without asking, kind of like a \"doomsday\" situation in Mega Man, so near and dear to my heart. So, what's happening now within that realm to control it? Like, are there steps being laid out? I know there's been a call for, I'm just using the word Congress like a Continental Congress kind of thing, but an international agreement that these are the steps we're going to take and all is that is.",
            "start": 1142.88
        },
        {
            "text": "just using the word Congress like a Continental Congress kind of thing, but a word like an international kind of agreement that these are the steps we're going to take. And all this is that is that achievable is that something that's being pursued actively? Yeah, they have put together sort of a uh a task force to discuss the ethics of of AI and Robotics as it moves forward. Um, but there's no greater framework that's preventing anybody from who innovates from from doing wrong with their technology. And what like what give me a few examples of like what could be wrong? Like, just as it just and it could be pie in the sky, I don't know. But like is it that far from what we see in sci-fi? No, I mean even with modern day robots, you know, a drone is is a very powerful tool. And you could you could put a weapon on a drone, you could strap an explosive to a drone and fly it into something. And that's a very real modern like there's no way to prevent that currently but it's still a possibility",
            "start": 1207.36
        },
        {
            "text": "put a weapon on a drone you could strap an explosive to a drone and fly it into something and that's a very real modern like there's no way to prevent that currently but it's still a possibility with the technology that we have so I think situations like that where we now have these devices that are capable of flying you know a 5 mile range and we can strap things to them that already an ethical concern in my opinion and so the idea then is that as things get more sophisticated so too the danger become more sophisticated okay so what is like what in your mind you know we were talking about KW specifically about I guess he he The Singularity is what 2045 he thought that and and that's basically when humanity is outpaced um does that date seem reasonable to you that the idea that we will we only have a few more decades until we create something that's smarter than us I think computers could be doing more advanced science and than humans by 2045 could be innovating more than humans just",
            "start": 1257.6
        },
        {
            "text": "only have a few more decades until we create something that's smarter than us I think computers could be doing more advanced science and than humans by 2045 could be innovating more than humans just because of their sheer computational power and ability to run more simulations concurrently than a human brain can and so kind of swinging it to a more positive sense like what kind of positive things can come out of that development like what like what could as opposed to the dystopian apocalyptic kind of **** that we focus on because it's interesting like well both sides are interesting but it's we have a compelling humans like it's like Book of Revelation like we have a compelling reason to just keep going back to this dark **** but what is the positive side of that like if assume the ethics are on the up and up assume um roboticist and and AI engineers and software engineers and everyone kind of come together and create something that's that's responsible what kind of",
            "start": 1315.64
        },
        {
            "text": "assume the ethics are on the up and up assume um roboticist and and AI engineers and software engineers and everyone kind of come together and create something that's that's responsible what kind of great science can come out of this that will help us in 20 30 40 50 years that you know is the positive side of it right I mean I think we could you know focusing on the science side um there're already robots that are kind of doing biology experiments basically you know doing the work that a PhD student who is very very highly trained um they basically pipet things all day long um and they're just running their experiments but their brain cycles should be used on other things a robot or an algorithm that's what they're made for is to do repetitive tasks so the more we can make these special purpose functional robots that can do these repeatable tasks in the real world or on our data um then the more it frees up human brains to do what human brains are best at doing which is thinking",
            "start": 1357.56
        },
        {
            "text": "Purpose functional robots that can do these repeatable tasks in the real world or on our data, then the more it frees up human brains to do what human brains are best at doing, which is thinking outside of the box being creative, coming up with novel solutions, which is where algorithms traditionally fail and kind of flipping the coin on its head. Because we talked a little bit about it, but at the same pace, like what gives me specific examples not today with drones and kind of every rudimentary strapping of explosives. What's the dire situation in 50 years if we don't control like what, like what do you see happening that could be so detrimental to humanity or to a society? One thing that worries me is that an AI could get so advanced that it could kind of kill the internet or affect the internet so much that global commerce and global communication came to a halt even for a little bit, and that would just be so tremendously bad. And it might not even be an algorithm that",
            "start": 1404.16
        },
        {
            "text": "the internet so much that Global Commerce Global Communication came to a halt even for a little bit and that would just be so tremendously bad um and it it might not even be an an algorithm that was intended to do that I think the the government could get involved in robotics and provide some sort of thing for people to use and they could have nefarious intents behind it so assume there's now self-driving trains cars all provided by a city by the government um they could be monitoring you they could be um infringing on your rights um and they could be vulnerable to attacks um to security exploits from other people um or or people who design those robots who have malicious intent I did read something that Uber was hiring hackers specifically to try to hack their cars and I assume that um this is something that they're always going to have to deal with they're always going have to be one step ahead and it seems like the guys on the other side of the fence that are on the Deep Web",
            "start": 1459.12
        },
        {
            "text": "this is something that they're always going to have to deal with they're always going to have to be one step ahead and it seems like the guys on the other side of the fence that are on the Dark net or whatever the **** they call it or these guys that are very smart and sophisticated that don't necessarily work for big companies that I don't want to say use their skills for evil I don't know if that's really true but this is more like kind of ambiguous agnostic Mr. Robot kind of **** that's going on right like I assume there'll always be one step ahead right like this this this probably can't be nipped in the bud there is going to be a cost of progress people are going to and I don't want to make it sound so dire people are going to die people are going to get hurt people are going to get maimed by robots and robotic things and AI or whatever but absolutely but presumably these will be learned from and we will be a better society as a result I assume right presumably and I think",
            "start": 1523.92
        },
        {
            "text": "get maimed by robots and robotic things and AI or whatever but absolutely but presumably these will be learned from and we will be a better society as a result I assume right presumably and I I think already there's a need for regulation you know self-driving cars the technology is there um the problems right now are people on the streets so if it was all self-driving cars we would be so fine um it's dealing with people with the uncertainty of humans acting alongside these robots um that sometimes makes it kind of a logistical nightmare um and that requires governments to become involved um you know if if we could outfit streets with sensors that would that would help self-driving cars a lot but the reality is we have built our physical world to not have technology in it and now we're trying to build things like self-driving cars that navigate that World um along with other people and that that can create kind of the most complications it sounds like uh Greg do you remember",
            "start": 1553.28
        },
        {
            "text": "we're trying to build things like self-driving cars that navigate with other people and that can create kind of the most complications it sounds like uh Tim do you remember what that specific website was remember when we did The GameOverGreggy Show about the driverless cars and the decisions they have to make do you remember what that was called can you find that for me yeah but wasn't that about ethics like the people's ethics well it was about no it was about the what what like what does it there was this website I don't do you know what I'm talking about where it's like the car is going to kill the human the baby or the human with the old woman but it has to do one of them right and it would ask a lot of people this kind of crowdsource the answer and say this is the ethical answer based on most humans and that and is it as binary as that like is I mean is that how they're going to have to learn is is through the experience of humans that seem",
            "start": 1612.84
        },
        {
            "text": "and say this is the ethical answer based on most humans and that and is it as binary as that like is I mean is that how they're going to have to learn is is through the experience of humans that seem flawed even at a moral an ethical level themselves in other words we are ethically flawed humans all of us that are now trying to make an ethical machine that makes ethical choices and it seems like it's only going to learn from the way we program them right but we're trying to build these machines in our image with the with the assumption that we are ethical beings even though that's not how our behavior often acts out it's fascinating actually and it's kind of it creates an interesting conundrum I've talked about in the past I don't know if it's scientifically sound or not that it seems like humans have outsmarted evolution in a sense and they're probably the only species that have done it because we obviously dominate the planet we are outside of our own Cradle of Life our own",
            "start": 1653.28
        },
        {
            "text": "humans have outsmarted evolution in a sense and they're probably the only species that have done it because we obviously dominate the planet we are outside of our own Cradle of Life, the Middle East, all these kinds of things have expanded and greatly affected everything around us. It seems like we are going to now create something - the next step of outsmarting evolution seems to be playing God in a way which is very fascinating and creates its own not so much ethical but religious and societal consequences that I think are fun to think about, and I'm sure there are professionals in your field that deal with only those things similar to bioethics and all that kind of stuff as well. Right? What um this question keeps coming back to my mind and it's a silly question but it's something our audience can kind of relate to - do you have you watched Westworld, yeah okay so that see the show reminds me what I've seen we're about halfway through it how",
            "start": 1698.92
        },
        {
            "text": "It's a silly question, but it's something our audience can kind of relate to. Do have you watched Westworld? Yeah, okay, so that see the show reminds me what I've seen. We're about halfway through it. How far away are we from something like that? Is that like 200 years away? Is that and I'm not saying we're going to have a theme park which people go to to experience you know human humanoid robots. What I'm saying is, like something that is so sophisticated that it is completely and wildly indistinguishable from anything in that we actually take pleasure in or use it in a commercial way. I think 100 years is a safe bet. We would probably have something indistinguishable from another animal in about a 100 years. It's pretty wild. Does it make you, as a roboticist today, does it make you? I've always wondered this about scientists specifically like the guys that worked on Apollo for instance, although that was a huge Quantum Leap. Does it make",
            "start": 1738.8
        },
        {
            "text": "does it make you sad that you're kind of setting this pathway for future roboticists in three or four generations to be able to do the work that you wish you could achieve right now, but still it is very necessary work? It's like Sir Isaac Newton figuring out that the Apple was falling at a specific trajectory that helps 400 years later a spaceship go to space. Whatever, um, it's frustrating but it's also exciting because the tools that we build, like the reason we can do such advanced stuff in robotics and AI today is because of the tools that were built by our forefathers in artificial intelligence, by the work they did, by the groundwork they laid, by their failed ideas, by their successful ideas. So while it's frustrating that I don't",
            "start": 1786.64
        },
        {
            "text": "by our forefathers in artificial intelligence by the work they did by the groundwork they laid by their failed ideas by their successful ideas um so while it's frustrating that I don't think I'm ever going to create a robot that is sentient and an artificial intelligence um it still doesn't make the journey any less exciting for me you know it's it's probably such an ignorant thing for me to even put forth but not being a scientist not having that education having a more Humanities driven kind of understanding of everything it seems to me that I I just I don't believe that it won't happen in your lifetime for some reason specifically because it's and again it's a very layman's kind of thing very ignorant kind of thing but it's like the microprocessor the leap to you know something like uh these imageless kind of computers in the mid-70s The Altair and all these kinds of things too to Apple I at you know at Berkeley to like it wasn't that long ago you know and like",
            "start": 1830.44
        },
        {
            "text": "like uh these imageless kind of computers in the mid-70s The Altair and all these kinds of things too to Apple I at you know at Berkeley to like it it wasn't that long ago you know and like it makes me wonder if if everyone's being a little safe in in their assumptions not understanding the implications of what you're talking about to nearly the depth you do but looking back only to you know our my my parents are in their mid-60s they were in their you know what mid 20s when the microprocessor was invented and then look at all of the things we have now and to me it's like I don't know like I like it would be awesome I I I hope you get to build that that device because it doesn't seem that outrageous for someone in their late 20s early 30s to be 60 and having built something that they didn't expect anymore than when you know Steve Jobs was finally crafting Macintosh that they thought that they would have the iPhone at near the end of his life you know so there are a few things that",
            "start": 1881.6
        },
        {
            "text": "expect anymore than when you know Steve Jobs was finally crafting Macintosh that they thought that they would have the iPhone at near the end of his life you know so there are a few things that would have to happen for me to say okay I think it's going to happen within our lifetime one of them is power technology batteries um have kind of really lagged behind Moore's law in terms of you know doubling every year um batteries are not getting that much better at a crazy rate um and we would need robots with a tremendous amount of power to go for a whole day um and so so power technology is one thing self repair is another like I said um most robots are meticulously craaed um and have to be serviced a decent amount of times um and so if some company started working on a robot that could repair itself um then I I might start getting a little more worried about about In Our Lifetime robots that could potentially um fix themselves and outsmart humans because outsmarting a human is one",
            "start": 1924.96
        },
        {
            "text": "repair itself, then I might start getting a little more worried about In Our Lifetime robots that could potentially fix themselves and outsmart humans. Outsmarting a human is one thing, but if you don't have any ability to affect the real world, then it's just all kind of hypothetical, right? Is it a safe assumption like the Assumption of a lot of AI and Robotics driven sci-fi that has a more dystopian slant, which is most of it makes the assumption that Humanity will see or robotics or robots or AI will see will see a system in which humanity is the only imperfect part of it, the one that's stying it from advancing further. Is that a safe assumption that that AI would come to, in other words, looking at you know because they are mathematically driven and they're looking at this",
            "start": 1987.6
        },
        {
            "text": "that's stifling it from advancing further is that a safe assumption that that AI would come to in other words looking at a you know because they are mathematically driven and they're looking at this very imperfect right-brained kind of humanity-driven philosophical being that they can't really comprehend that's in the way is that a safe assumption that that you know or is that a logical assumption that an AI would see humans and be like we want to eradicate you not because we hate you but because you are an annoyance to the system working and functioning properly I think I think it's a realistic conclusion given that humans are very self-destructive and we're harming the planet where we basically take resources reproduce too much um and I think that maybe if a if an algorithm realized some fundamental nature about the universe um and realized that human beings were detracting in some way from the universe that's that's why these sci-fi writers come to these conclusions is because",
            "start": 2044.72
        },
        {
            "text": "fundamental nature about the universe um and realized that human beings were detracting in some way from the universe that's that's why these sci-fi Writers come to these conclusions is because ultimately we are doing harm to the world and to ourselves and if we built a perfect organism that could act like we all want to act then it might be its logical conclusion that we should get rid of all nonperfect organisms yeah it seems like a scary but it seems it seems logical to me not understanding exactly how the algorithm would work or how an AI would necessarily think that it would look at the imperfect components and try to remove them um so it is it does it makes sense to me but I didn't know if a scientist looks at some of these things and it's like this is this doesn't really make any sense at all it's kind of nonsensical so it sounds like there's some some you know when there's smoke there's fire it seems like there's some some element of truth to it I think",
            "start": 2093.8
        },
        {
            "text": "really make any sense at all it's kind of nonsensical so it sounds like there's some some you know when there's smoke there's fire it seems like there's some some element of truth to it I think so the other thing I want to touch base with you on uh before we go is um the idea of um robotics in AI affecting humans and the way humans are uh moving forward in other words we're talking a lot about robots being crafted from you know from clay basically that they're we're building them from the ground up and we're and we're programming them is there a future for Robotics and or Ai and I think it's more probably AI Centric but robotics would play a role in it where we meld with them and some sort of way where it's like we are no longer you know we are no longer human in in a in a sense I think that's a much more realistic uh short-term future for us that we will augment our bodies um that it will be common place to see um robotically or AI augmented people out on on the street and you",
            "start": 2148.08
        },
        {
            "text": "that's a much more realistic uh short-term future for us that we will augment our bodies um that it will be common place to see um robotically or AI augmented people out on on the street and you already see that today um Hugh Hurd one of the professors at the MIT Media Lab where I studied he basically lost his leg in a climbing accident and he wasn't a scientist at the time and he decided he he was a climber like a full-time climber and he decided I'm going to spend the rest of my life building robotic limbs because I no longer have a leg and he's now a better climber because he can have a longer reach with his leg he can have a smaller foothold so we're already seeing you know real augmentations of people's bodies using robots um and I don't expect that to change in the next next 20 years and the more we kind of put the tools for building robots into normal people's hands through the maker movement through things like that um I think people will start experimenting with augmenting",
            "start": 2191.12
        },
        {
            "text": "and the more we kind of put the tools for building robots into normal people's hands through the maker movement, through things like that, um I think people will start experimenting with augmenting their own bodies with gadgets. Is there an equal ethical concern there? Kind of a different one actually, but an equal weighted ethical concern about what people will do to themselves and like the idea of kind of losing your humanity, controlling things that were not meant to be controlled. I think so. But it seems like it's yes, and again you're giving one person kind of the control over this system, so if this person is malicious they could do harm with it. Um, so it's still kind of all centered around humans making bad decisions, humans who are malicious and want to use technology for bad. That's always going to be around, but it can also do a lot of good. So where do you see that kind of going in the next 10, 20, 30 years in terms of the way it affects and interfaces with us as humans in terms",
            "start": 2246.08
        },
        {
            "text": "always going to be around but it can also do a lot of good so where do you see that kind of technology going in the next 10 20 30 years in terms of the way it affects and interfaces with us as humans in terms of like could it could could a blind person see could a could a deaf person hear I mean we already see that with cochlear implants and stuff like that and I know that that that surgery is getting very sophisticated now in terms of identifying reasons uh repairable reasons people might go blind um but is that possible is it possible to have a robotic eye that somehow interfaces with your brain and your brain doesn't know that it's not your eye or I know we already see what people trying to clone organs and do all these kinds of things and I know that there's a lot of different ways a more biological driven way to go about it but is it not fair to say that a robotic driven way of repairing people's problems is is probably going to be the norm yeah as you",
            "start": 2299.72
        },
        {
            "text": "a lot of different ways a more biological driven way to go about it but is it not fair to say that a robotic driven way of repairing people's problems is is probably going to be the norm yeah as you said yeah definitely it's interesting to me because I don't know how I feel about it like I like it's it's is it going to be we talked about this a little bit in um you're you play games it's Mass Effect I'm sure you've played um there are all sorts of different species and all sorts of different you know gadgets and and whatnot or whatever but is there not something quaint about the human who's human you know who isn't who is untouched and unscathed as he came from the primordial ooze himself right um as opposed to and I don't know how I feel about that like do you think that that there's something to that or you think that that's kind of um primitive human rationalization standing in the way of one of the great things that we have which is progress like unlimited progress well I think",
            "start": 2339.8
        },
        {
            "text": "to that or you think that's kind of primitive human rationalization standing in the way of one of the great things that we have, which is progress - like unlimited progress. Well, I think we are evolutionarily, we've haven't had to survive for so long as a species that we haven't advanced as much as a species. It's very easy to stay alive as a human now compared to a thousand years ago, and you know, you think about a thousand years before that and a thousand years before that - it is really easy to exist now. So I think people are thinking a lot more about how to not just exist as a human but to be better than a human, to be faster, to be smarter, to be stronger, and that's where the augmentation is really the motivating factor. Is that people have all these extra brain cycles and all this extra time to do whatever they want to do instead of survive. And we want to be better - yeah it seems it seems logical and rational to me but there seems to be something very romantic about",
            "start": 2381.44
        },
        {
            "text": "all this extra time to do whatever they want to do instead of survive um and we want to be better yeah it seems it seems logical and rational to me but there seems to be something very romantic about what's being lost as well like we seem to be at some sort of in my personal estimation we've talked about this I think on our on our show before but we seem to be at some sort of generational leap that is very unique in human history and and we can go back to obviously uh Cro-Magnon and Neanderthal and the things the crazy things that were going on in their lives and how they met and the Cro-Magnon were smarter and and but there's a little pieces of Neanderthal in us you know and I wonder if we've come to some sort of place in society where there's going to be a purist movement where there's going to be a movement in 50 years where people don't it reminds me of that that Black Mirror episode I don't know if you watch black mirror with the episode of the where they all have those those",
            "start": 2438.44
        },
        {
            "text": "going to be a movement in 50 years where people don't have it reminds me of that Black Mirror episode, I don't know if you watch Black Mirror with the episode \"The Entire History of You\" where they all have those eyes that can rewind and look at things, but that one girl doesn't. And uh, if we're going to look at people like that and think that they're weird or that there's something kind of pure about it because they didn't succumb to the rash of technological advancements that add life or utility to our lives, well, think about somebody who doesn't have a smartphone. There are pros and cons to it; they are probably much more aware of their physical surroundings, much more social. Um, but if you want to send them money, good luck. Um, if you want to take a video right away, good luck. So there are pros and cons to all of these technologies, and I think there will probably be some movement that fights back against this if there's not already; you know, there are",
            "start": 2482.44
        },
        {
            "text": "away good luck so there are pros and cons to all of these technologies um and I think there will probably be some movement that fights back against this if there's not already you know there are researchers um Sherry Turkle is uh basically a Harvard psychologist who looks at why technology is taking us farther away from each other um why technology is separating humans and making us more alone um yeah and it is I mean it's true I mean like I feel like you and I and and many of our viewers and the people that work at Kinda Funny and and our and our contemporaries our peers just in that in that in in the age we're at in 2017 I think if you're maybe between 25 and 35 or 40 this unique nexus uh between uh the way things were and the way things are going to be and that we are the generation the last generation of members who actually lived in that world right um and but also advancing forward into a world as some of the pioneers knowing that we're changing it",
            "start": 2526.08
        },
        {
            "text": "Generation Our member is the way things were right um and that actually lived in that world right and but also advancing forward into a world as some of the pioneers knowing that we're changing it knowing that if I thought about myself when I was seven in 1990 or whatever that none of this was happening like this, this was far from what we had. We were playing NES and we had maybe if you were lucky you had a 386 in your house if you were you know if you had some money and you used the phone on the wall in your kitchen and you didn't know what the hell the internet was cuz it didn't exist yet, but the worldwide web didn't exist yet. And robots were something that you read about in Isaac Asimov novels. It seems like things have advanced so quickly and this specific generation is going to be a pivotal one. I don't know if you agree in terms of you know I talked to Adam about it where we were talking and I'm like I feel like we're going to tell our",
            "start": 2584.08
        },
        {
            "text": "generation is going to be a pivotal one, and I don't know if you agree. In terms of, you know, I talked to Adam about it where we were talking, and I'm like, I feel like we're going to tell our grandkids that they're going to look at our lives now as so quaint nonetheless the way the lives will be, you know, the way the lives were pre-this, where like we had this thing where we called someone, and they actually a person actually came and picked us up. You know? Five years ago, that would have been like unbelievable. Greg and I were talking about that, where it's like it seems so Uber-like back in the day, and then we had a person, and then in a few years, people aren't going to pick us up anymore; now a car is just going to arrive, we're going to get in, we're not going to talk or interface with anyone, and we're going to get out. And they're going to look at that particular moment as so quaint because they're like, \"You called a person who drove a car,\" and I don't know... it's I love it",
            "start": 2624.16
        },
        {
            "text": "with anyone and we're going to get out and they're going to look at that particular moment is so quaint because they're like, you called a person who drove a car, and I don't know, it's... I love thinking about that kind of stuff. And I really do feel like this - maybe it's just my mom always said, \"It's like every generation thinks they're the most important, and every generation thinks they're seeing the end.\" And I'm like, but I just do feel like there's something about this... you know, about this age. And I mean, I think there is - there are printers. I think printers will be completely foreign to our kids. Um, printing out digital information on a piece of physical paper - like MapQuest. Do you remember having to print out a map and put it in your car and... like you had to plan? You now don't have to plan because of technology; everything happens for you. So I think a lot of the while future generations might look back and think it's quaint, but I think the danger is that they",
            "start": 2658.6
        },
        {
            "text": "now do not have to plan because of technology everything happens for you so I think a lot of the while future generations might look back and think it's quaint I think the the danger is in that they are not going to be thinking for themselves um because everything will be so easy yeah and that is scary and maybe that is an evolutionary challenge that we have to confront as well that things become yeah too easy and then normal everyday or or even catastrophic events will become more harder to overcome as as we succumb more and not necessarily to group think I don't think but just group think in the sense that we would rely on AI or rely on computers rely on the internet MapQuest is a great example because in the late 90s yeah in the early 2000s you would print out you go to a concert I remember going to a concert at Jones Beach on Long Island my friend we printed out directions to they were totally wrong but we printed them out we got lost and all that kind of stuff and then Garmin",
            "start": 2702.72
        },
        {
            "text": "to a concert at Jones Beach on Long Island my friend we printed out directions to they were totally **** wrong but we printed them out we got lost and all that kind of stuff and then Garmin and all these guys started being like oh you can have a GPS in your car and they built them in the cars and now like no one uses GPS and now you have a phone right and that's the same reason why I think that like we collectively as a society are understanding how just how **** quick we're accelerating not advancing but accelerating which is why I'm confident and I'm hopeful that you get to build like the whatever dream has been in your mind since you're a kid I hope that you get to build it because I just I just feel like all the evidence even though smart people like yourself are like well we have all these major hurdles to overcome the more layman guy like me is but but but I'm like but look around you you know like I just don't I just can't this flat screen TV is worth",
            "start": 2747.92
        },
        {
            "text": "are like, well, we have all these major hurdles to overcome. The more layman guy like me is, but, but, but I'm like, but look around you, you know? Like I just don't... I just can't believe this flat screen TV is worth almost nothing that we're looking at for our commiserate monitor right now. Ten years ago, yeah, that would have cost $23,000, you know it's true and it would have been 720p and it would have been terrible and it would have been thick. CRTs are going to be these things that no one even remembers. So I'm excited about the future because I'm interested in it whether it goes bad or not. I actually don't even know if I care because I just want to see what happens, it'll be different, it'll be different, it'll be exciting. Uh, the last thing I wanted to ask you, I know I said that a while ago but one thing that came to mind for me and I don't know if you can speak to this but this is something that's interesting to me as well is the digitization of The Human Experience, of the mind, of memories.",
            "start": 2784.2
        },
        {
            "text": "one thing that came to mind for me and I don't know if you can speak to this but this is something that's interesting to me as well is the digitization of The Human Experience of the mind of memories is this something that's possible and is this something that's going to to to come to fruition in terms of helping AI Advance more or in terms of embodying a robot with the actual human or the idea of never dying and all these kinds of things that people talk about in very kind of American you know American Scientific Frontiers kind of ways where it's like are these things happening can someone plug something into me one day and and see what I'm thinking can they plug something into me and see what my memories are is a way is that digitized in a way that a is the brain digitized in a way that a computer can understand or is that something that they're trying to work on interfacing we still don't know that um but I think digitizing information is a very interesting um application where",
            "start": 2826.0
        },
        {
            "text": "a computer can understand or is that something that they're trying to work on interfacing we still don't know that um but I think digitizing information is a very interesting um application where robotics and AI is super relevant right now I mean imagine if you just had a bunch of cameras in your home and they recorded everything and you could search them by keywords or by date and you could resolve any argument that happened in your home by getting a ground truth that was the actual interaction that happened you know that would be a technology that could both be negative and positive you could have a memory like a physical memory of everything a video of opening presents on Christmas morning um it might not be from your perspective but it would be a record of it um and I think that type of kind of everywhere like cameras and microphones everywhere that will happen in our lifetime you know everything is going to be recorded in our lifetime so it's a similar ubiquity that you were",
            "start": 2864.16
        },
        {
            "text": "of Kinda Funny everywhere, like cameras and microphones everywhere, that will happen in our lifetime, you know. Everything is going to be recorded in our lifetime, so it's a similar ubiquity that you were talking about with uh with data-driven internet-driven kind of things for AI, the same kind of observing human interaction or human activity, human interaction right, just being optically and ably as yeah, and in terms of interfacing with the brain, that's just still such a we still don't really know much about the brain. Um, which is fascinating because you were saying that in order to make a a fully-fledged AI, which might be one of the things, one of the hurdles you were talking about, is is that we need to replicate every part of the brain and it seems like we understand very little about it. Well, that that is one assumption that kind of classical founders of artificial intelligence took a very biologic-inspired approach, is that you know we need to know how humans think and emulate that but",
            "start": 2916.96
        },
        {
            "text": "that is one assumption that kind of classical founders of artificial intelligence took a very biologic inspired approach is that you know we need to know how humans think and emulate that but actually the biggest advancements in AI in the past 10 years are nothing to do with how humans think um even though they're called neural nets and they're kind of inspired by the way a brain has neurons um they are very very carefully crafted by humans um instead of grown and and kind of instead of um learning from experience while they do do that there's a lot of bootstrapping that has to happen and that happens in the brain too we just don't know how it happens so even if we knew how the brain learned um we might not know what the assumptions were that that would allow for that learning so there's kind of a a a chicken and egg problem that we both need to know how the brain learns and grows over time but we need to know what is hardcoded to what is you know what what comes when you're",
            "start": 2959.6
        },
        {
            "text": "there's kind of a chicken and egg problem that we both need to know how the brain learns and grows over time but we need to know what is hardcoded to what is you know what what comes when you're born I wonder if this might be a super ignorant thing to say but also like the more primitive nature of the brain in terms of like the brain stem the breathing that the like the things that we we don't even know how we control or we don't think about we know how it happens but that that might not even really need to like we don't in other words we don't need to replicate the entire brain because there's just things in the brain that an AI wouldn't need or a robot wouldn't need anyway and so maybe it makes more sense for the human to craft it right in the image that in in which it it it it fulfills the functions that it was designed to fulfill right without having to worry about this primitive stuff that comes from right and and that's why robotics is so functional now is because",
            "start": 3019.16
        },
        {
            "text": "it fulfills the functions that it was designed to fulfill right without having to worry about this primitive **** that comes from right and and that's why robotics is so functional now is because people say um you know I want to build this general purpose AI and huge failure but you say I want to build a robot that cleans the floor and 10 years of hard work will get you there um and so very application specific very you know a thing that needs to be solved that's easy to do but to create a thing that can solve all things that's kind of what I don't think is going to happen within our lifetime because that is fundamentally what makes humans special cool we'll leave it there I think that I think this was fascinating I was super interesting and super uh thought-provoking and I hope it provoked thought for you guys out there as well um you know I like that nerdy **** I know a lot of you guys like that stuff as well and Adam's perfect for that so we appreciate you coming thank you so",
            "start": 3061.88
        },
        {
            "text": "thought for you guys out there as well um you know I like that nerdy stuff I know a lot of you guys like that stuff as well and Adam's perfect for that so we appreciate you coming thank you so much thanks for having me calling uh and remember well if you're watching this or listening to this you already subscribed to us on Patreon um but you know uh I hope you enjoyed it I want to do more things like this in the future so uh give us your feedback Keep It Coming uh hope you guys are doing well happy new year since this is the first episode uh of the new year and uh we'll see you next time thank you",
            "start": 3107.64
        }
    ]
}