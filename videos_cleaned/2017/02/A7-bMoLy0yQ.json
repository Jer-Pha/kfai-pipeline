{
    "id": 2435,
    "video_id": "A7-bMoLy0yQ",
    "show_name": "The GameOverGreggy Show",
    "hosts": [
        "Adam Setapen",
        "Colin Moriarty"
    ],
    "title": "Robotics, AI, and an Uncertain Future - The GameOverGreggy Show (Patreon Exclusive January 2017)",
    "description": "Colin's friend Adam -- an MIT-educated roboticist -- comes to the studio to talk about what he does for a living, to wax poetic about the future of robots and artificial intelligence, and to discuss why we should be both excited and horrified of what's to come.\n\nSubscribe! http://www.youtube.com/kindafunny?sub_confirmation=1\n\nSupport us and get the shows early here! http://www.patreon.com/kindafunny\n\nCheck out our store! http://www.kindafunny.com/store\n\nFollow us on Twitter!\nGreg - http://www.twitter.com/GameOverGreggy\nColin - http://www.twitter.com/NoTaxation\nTim - http://www.twitter.com/TimGettys\nNick - http://www.twitter.com/Nick_Scarpino\nKinda Funny - http://www.twitter.com/KindaFunnyVids\n\nEvery day Greg Miller, Colin Moriarty, Tim Gettys, and Nick Scarpino talk about the biggest stories in nerd culture.",
    "published_at": 1488117600,
    "duration": 3133,
    "transcript_chunks": [
        {
            "text": "Greetings and salutations, welcome to an exclusive episode, a Patreon exclusive episode of The GameOverGreggy Show. My name is Colin Moriarty. I'm here with my friend Adam Setapen, who's a roboticist, and I wanted to do this episode today inspired by a dinner Adam and I had a month or so ago, because I bring up these nerdy topics on The GameOverGreggy Show, which is our flagship podcast that you guys probably watch. I'm sure that we've been doing for a few years, and the idea of the show, Adam, in case you've never seen it, and there's no reason why you should have, is because we do basically four topics a week that are just random and unassociated with each other. So it could be about someone's like, I like to cook beef, and then the other person's like, I like looking at stars, and then the other person's like, you know, and all that kind of stuff. And I bring up often these nerdy AI and robotics and kind of futurist kind of things on the show that no one cares about but me, and then you and I",
            "start": 0.0
        },
        {
            "text": "person's like, you know, and all that kind of stuff. And I bring up often these nerdy AI and robotics and kind of futurist kind of things on the show that no one cares about but me, and then you and I had dinner with our girlfriends. You date my girlfriend's cousin, and we went out to a mini golf course bar, Urban Putt, Urban Putt, right, which was very fun. And I, you and your buddies, you went to MIT, and your buddy, you know, some of your friends from MIT were there, very smart group of people. And I was picking your brain, and I felt like I was being annoying, so I stopped, and I was like, we, I'm going to have you on our show in the coming months to do something about what you do and what you know, because you know so much, and you're so smart, and I have an admiration of people much smarter than me, and you're one of those people. So, first of all, you were, you had your, you got your bachelor's degree down in Texas, but you went to MIT, right, for grad school, is that that",
            "start": 39.84
        },
        {
            "text": "much smarter than me, and you're one of those people. So, first of all, you were, you had your, you got your bachelor's degree down in Texas, but you went to MIT, right, for grad school, is that that, is that correct? Yes, MIT, of course, is Massachusetts Institute of Technology, one of the great schools in the world. Very awesome, you go there. His girlfriend went to Harvard, my, my, my girlfriend's cousin, so a pretty smart, pretty smart group of people. And you are in robotics, which is fascinating to me, and you understand AI, and you understand all these things, and you work very intimately with these kind of components here in Silicon Valley. I'm just started a new job, and what, what is your title at that job? I am a Senior Robotics Engineer for Mayfield Robotics. We make this little social robot named Curry, and he's, he kind of is a home helper, think of Amazon Echo with wheels or Google Home with wheels. Yeah, that's awesome. Okay, so when I found out that this is what you did, I",
            "start": 80.04
        },
        {
            "text": "robot named Curry, and he's, he kind of is a home helper, think of Amazon Echo with wheels or Google Home with wheels. Yeah, that's awesome. Okay, so when I found out that this is what you did, I immediately, my girlfriend Ain, who you guys know, I immediately started asking her questions about you, because I'm like, well, said you went to MIT, and he's in the robotics, he's so smart, because I like to read about these things. As I often say, I've always been fascinated by science, and have, I think, a better than layman's understanding of certain things, but I don't understand the math, I don't understand the theory, understand that kind of stuff. What I do is I read the books of people explaining this thing, and I trust that the math and the science behind it is good, because I certainly can't prove it, right? You obviously have a much deeper and more thorough understanding of it, but also are able to talk in a very eloquent way about the ramifications of AI, the ramifications of robotics in the",
            "start": 119.4
        },
        {
            "text": "it, right? You obviously have a much deeper and more thorough understanding of it, but also are able to talk in a very eloquent way about the ramifications of AI, the ramifications of robotics in the future and futurism. So I want to just, and as I told you beforehand, because this is my mant, and people that have been listening to me for years know, is I don't prepare notes for interviews, I don't prepare for interviews. I know what you do, and I know like what to, where to start, and then we'll see where it goes. So I want to know, I want to start in a very specific place. Okay, are things about to get scary? I think things are not about to get scary, but the potential of them getting scary is very real, and is kind of festering in people's minds, and I think people are making more of the implications than they are today in terms of robotics, in terms of AI. I think things are getting a little more scary, but a robot takeover, very unlikely. Okay, so where, where do we stand right now with AI and with",
            "start": 155.8
        },
        {
            "text": "they are today in terms of robotics, in terms of AI. I think things are getting a little more scary, but a robot takeover, very unlikely. Okay, so where, where do we stand right now with AI and with robotics generally? What is the focus? We hear a lot about driverless cars, which seem to be a year, two, three years away from real fruition, right? A lot of companies seem to be investing a lot of money in them, Google, Apple, a bunch of companies, who knows like what's real, what's not, right? With that, because it's a lot of very secretive kind of stuff. We have AI becoming more, not sentient, obviously, but more useful, I guess, definitely. And we have these kind of, this kind of, this collaboration between the more robot, like the engineering side, robotics, along with the, the more programming side and software side, AI, that's becoming symbiotic with each other. So where do we sit right now? Like what's going on in your field? What's going on in your world? What are you guys focusing on? So a lot of the huge",
            "start": 202.0
        },
        {
            "text": "side AI that's becoming symbiotic with each other. So where do we sit right now? Like what's going on in your field? What's going on in your world? What are you guys focusing on? So a lot of the huge breakthroughs in AI that Google and Facebook and places like that have been spearheading is because of the massive amounts of data that the internet is providing to them. So they have these algorithms that can be trained by all this data, and they can predict things very, very well. But what is so difficult about robots is, and kind of the difference between AI maybe in a video game and AI on an actual robot is in robotics, we, we can break it down into three things: sense, plan, and act. And sense is kind of sensing the world, detecting everything around you, having sensors that say that's a wall over there, there's a person here. In video games, that's all done for you. You have complete knowledge about the world. All the AI does, planning is kind of the AI part, and that's gotten a lot",
            "start": 246.08
        },
        {
            "text": "wall over there, there's a person here. In video games, that's all done for you. You have complete knowledge about the world. All the AI does, planning is kind of the AI part, and that's gotten a lot better recently because of all this data. And then acting in the physical world is another problem. In video games, it's very easy, but in the physical world, robots break down, and they're weird events, like a robot might go over a little lip and fall over, and it can't get up, and then it's done. So that's kind of one of the big differences between AI as software and AI on robots is it takes a whole lot of engineers to keep something running in the physical world. But if it's an algorithm, it can maintain itself. So that's why I think the potential of, you know, disaster with robots is low, but with AI is, you know, it's, it's higher, we'll say. Okay, so what is the practical application of what you guys are working on now? You're talking about, you know, this part, this specific kind of housekeeping or",
            "start": 293.24
        },
        {
            "text": "AI is, you know, it's, it's higher, we'll say. Okay, so what is the practical application of what you guys are working on now? You're talking about, you know, this part, this specific kind of housekeeping or house-helping robot that you have. Things seem to be quite modest compared to what we see in sci-fi with the Cylons or the droids in Star Wars or whatever that are like borderline sentient and can obviously do more, I guess, developed tasks. And then you see videos from guys like Boston Dynamics that are seem to be making like Metal Gear type robots that are a little more scary, right? What, like, where are we practically right now? And then where do you think we're going to be in the next few years? Like how much of a quantum leap are we going to take? Because my assumption, and I don't know if it's accurate or not, is that we couldn't imagine having these smartphone, we, we couldn't even imagine what a smartphone was 10 years ago, and then when they came out, they slowly seeped our minds, and now they're",
            "start": 344.84
        },
        {
            "text": "or not, is that we couldn't imagine having these smartphone, we, we couldn't even imagine what a smartphone was 10 years ago, and then when they came out, they slowly seeped our minds, and now they're, they're part of not only the phone itself, but everything we do, whether it's Uber, whether it's the way we communicate and all that kind of stuff. Are we, are we at a similar kind of Through the Looking Glass situation with this kind of stuff where we're getting, where it's going to advance quicker in terms of AI? Yes, in terms of robotics, it's hard to say, because it takes so much to maintain something that works in the physical world. A robot can't fix itself. Generally, like when you see Boston Dynamics prototypes, that's one prototype that probably a team of 50 engineers has worked on for, you know, two to three years to make a demo or to make something that's useful. And in terms of what people want in their actual homes, when we look at robots, there's basically Roomba, the robotic vacuum cleaner, and",
            "start": 382.04
        },
        {
            "text": "to three years to make a demo or to make something that's useful. And in terms of what people want in their actual homes, when we look at robots, there's basically Roomba, the robotic vacuum cleaner, and from the time that Roomba was released, basically 10 years before that, the founder of iRobot was basically churning on this idea, trying to create something reliable enough that could exist in a person's, in a normal person's home, clean it up decently well, charge itself, and provide a functional task to the person. Now, what's, what's kind of in this gray area is what I focus on, which is social robotics, robots that are meant to interact with people, how those robots should interact with people, and how we should design those robots to be appealing to people, because we've seen that, you know, there's this kind of weird uncanny valley. If you make a robot too humanoid looking, it gets creepy looking. But if you make a robot simple and emotive, it can be very effective at conveying information",
            "start": 424.48
        },
        {
            "text": "this kind of weird uncanny valley. If you make a robot too humanoid looking, it gets creepy looking. But if you make a robot simple and emotive, it can be very effective at conveying information to a person. Okay, so is it, because I had one of those Roomba, my old roommate a long time ago had one. We were fascinated about, come home every once in a while, I'll be stuck somewhere dead, like under the treadmill or whatever. Is that the first like practical robot that we had in our, in our houses? I mean, is that like when you guys look back at, at the robotics or AI or whatever, is that really the first one of consequence? Yes, yes, I think it is. And drones aren't really household robots, but I think that's the second big consumer segment of robotics that provides a function, aerial video, and you can use that output in lots of different and novel ways. So that's more of an enabling robot than a Roomba, because, you know, you can take awesome footage of somebody surfing from a drone, or you can use it to",
            "start": 479.12
        },
        {
            "text": "output in lots of different and novel ways. So that's more of an enabling robot than a Roomba, because, you know, you can take awesome footage of somebody surfing from a drone, or you can use it to map, you know, a developing world from above. So it's more of a democratizing technology than a robotic vacuum cleaner, and I think we'll see some very interesting trends in drones in the next few years. So with, with the AI like kind of segment of it, because we were talking a little bit about, you know, well, something's very primitive like Siri or, what, what Microsoft's doing with Cortana, and then obviously like this Alexa stuff that's going on with, with Amazon right now. You got like, I'm not sure it's not your job, but you have probably marketers or people that are more marketing centric or more in the weeds with like what people want in terms of like out of these robot. Is that, is this what you guys are finding that people want something that's like, you could just say like, Alexa, I need",
            "start": 528.0
        },
        {
            "text": "in the weeds with like what people want in terms of like out of these robot. Is that, is this what you guys are finding that people want something that's like, you could just say like, Alexa, I need flowers because I burned something in my wife's house and she's going to be mad at me? Like, is that really what people are finding, or is there something like, is that basically a stop gap until we can figure out something more, more novel for today? Right, in the home, people really want to use voice and speech as an interface to everything, because you're safe. You don't, you know, if I'm walking down the street and I say, hey, Siri, order me something explicit, and somebody hears me, that's weird. I might not actually want to use voice as an interface. I might just want to pull out my phone, order it. But in, in the home, in your car, you're more comfortable. So voice is a really natural interface to, to interact with your devices, with your data, stuff like that. So I think that voice is a great interface for",
            "start": 574.0
        },
        {
            "text": "the home, in your car, you're more comfortable. So voice is a really natural interface to, to interact with your devices, with your data, stuff like that. So I think that voice is a great interface for robots, but I don't think robots are necessarily ready to talk to people, because that changes the expectation of what the robot can do so much. You know, a cat or a dog responds to your voice, you can train it to go over there, you can, it knows its name, but it's not going to respond to you through voice. So that's kind of what we're trying to do with robotics now, is lower the expectations so people are willing to use these interfaces that are not nearly as futuristic or advanced as people are used to seeing in movies and TV. Interesting. One of the major things you and I remember talking about during that, you know, we were, we were drinking, we were eating, we were having a good time, was, well, two things I remember specifically, we were talking about the Turing Test, which I'm fascinated about, and we",
            "start": 616.32
        },
        {
            "text": "that, you know, we were, we were drinking, we were eating, we were having a good time, was, well, two things I remember specifically, we were talking about the Turing Test, which I'm fascinated about, and we were also talking about, well, the Turing Test in specifically with, we were talking about Ex Machina and all these kinds of ways that we've seen it play out in fiction and the expectations of that, in particular. But the other thing we were talking about was Ray Kurzweil and Singularity, and the, the idea that computers are, you know, when, when computer intellect becomes or grows to a pace where it's going to, where they're going to outsmart humans or whatever on a presumably a permanent basis. And that's kind of where I wanted to steer this, because this is where things get kind of, I don't want to say like dystopian, but they could get dystopian, but it's just interesting about where we're going with this. One of the fascinating things you told me about the Turing Test, and for people that don't know, Turing",
            "start": 666.64
        },
        {
            "text": "but they could get dystopian, but it's just interesting about where we're going with this. One of the fascinating things you told me about the Turing Test, and for people that don't know, Turing Test is when a computer, well, you can explain, it's when a computer can out-convince a person that it's real, right? Is that, yes, so, so basically, the, the classical Turing Test is, there is a room that you can't see into, and you write down something on a piece of paper and slide it under the door, and then you get a piece of paper back, and it's a response, and you basically have a conversation. It was either generated by a computer or a human, and at the end of this, the person is supposed to say, I think this was a computer, I think this was a human. And an algorithm passes the Turing Test if it can fake out 50% of people. So if it can convince more than half of the people that it is a human, then it's indistinguishable from a human. So that's the classical Turing Test, it's just with text.",
            "start": 705.36
        },
        {
            "text": "can fake out 50% of people. So if it can convince more than half of the people that it is a human, then it's indistinguishable from a human. So that's the classical Turing Test, it's just with text. Kind of a more modern Turing Test is having a face-to-face conversation with a being and trying to figure out if that being is a robot or not, right? And you were saying that, and this isn't surprising to me, I guess, but that we are imminently close to the former, but very far away from the latter, right? That's what I would think. I mean, we are very, very close, and in fact, some people have claimed to have, have beaten the Turing Test basically with algorithms. But in terms of talking to a conversational robot, we're not there at all. Okay, and, and that's just to be clear, you did, you call the screen door, was that the, the term you use, or is it like where, like the, the former would be called that, I guess, right? Where you can't like, but is there not an intermediary step between talking to it",
            "start": 750.12
        },
        {
            "text": "screen door, was that the, the term you use, or is it like where, like the, the former would be called that, I guess, right? Where you can't like, but is there not an intermediary step between talking to it, but not like to hearing and communicating with it in some sort of verbal way, but not seeing it? Is that something that's like kind of intermediate and could be passable before? Yeah, absolutely. And I, I think it will be, you know, with, with all this data going into Alexa, Google Home, all these things, they're capturing all that data, and that's very useful to them. Anytime you say, hey, Alexa, blah, blah, blah, it records what you say. And even though the computer voices are not very advanced right now, they're getting massive amounts of data of real people speaking, and the voices are going to get much more emotive, much more realistic in the future. And I think we'll start to see conversational interfaces that could pass the Turing Test with speech, you know, you're just talking to an entity,",
            "start": 803.56
        },
        {
            "text": "much more emotive, much more realistic in the future. And I think we'll start to see conversational interfaces that could pass the Turing Test with speech, you know, you're just talking to an entity, and it might sound and act exactly like a, but it could be an algorithm. And this uncanny valley problem is the reason why, according, in addition to, I guess, the limits of robotics as we know it now, is the reason why I couldn't sit in a room like Ex Machina and talk to someone and be tricked. I guess we're, we're very far away from that. You would assume we're like lifetimes away from that, or it's hard to say. AI and robotics started in this, you know, 50s, 60s, 70s, and they, they said it would be solved in 10 years, and they were very confident in that. And obviously we are not there yet. When you look at androids, which is a humanoid robot, that's trying to look like a human, they look creepy. There aren't that many of them that look natural. When they speak, you can tell there's something",
            "start": 852.84
        },
        {
            "text": "you look at androids, which is a humanoid robot, that's trying to look like a human, they look creepy. There aren't that many of them that look natural. When they speak, you can tell there's something different about them. I, I don't think much about that is going to change in the next 10 years, but I could be wrong, right? Yeah, because it goes back to this idea of the acceleration, not only, I guess, Moore's Law kind of stuff, but the acceleration of, we had these, you know, we had, you know, Mac and Lisa and all these things that really advanced to a 486 very quickly, which really advanced to a Pentium processor even quicker, which then advanced. And so I guess the idea, but it seems to be a more aesthetic thing, and a more, and this is much more complicated than making a personal computer or making a phone, so it's much more dynamic kind of thing. So I understand why you guys could, could reach that, you know, as a lay, could reach that conclusion that it seems almost impossible. Well, it's, it's basically, you have",
            "start": 903.88
        },
        {
            "text": "much more dynamic kind of thing. So I understand why you guys could, could reach that, you know, as a lay, could reach that conclusion that it seems almost impossible. Well, it's, it's basically, you have to emulate everything about the brain and about the physical magic that is a human being. You know, we are very special creatures with emotive faces that are very complicated, and even building a face that can emote like a human's is a very difficult task, not to mention having it infer emotions about the other person. You know, if I'm talking about that water bottle and I point at it, you know what I'm talking about. But grounding a robot in the physical world, linking words you say to objects in the physical world, we're still a very long way from that. So talk to me a little bit about, you know, I guess we'll get into the meat and potatoes now, specifically about the advancements in AI and how they can be useful, but also how they can be detrimental or scary. And I'm not talking necessarily, we",
            "start": 954.36
        },
        {
            "text": "I guess we'll get into the meat and potatoes now, specifically about the advancements in AI and how they can be useful, but also how they can be detrimental or scary. And I'm not talking necessarily, we talked about the Cylons or Skynet or any of these kinds of things, but it's like, it seems like smart people, whether it's Elon Musk, and I'm talking about just not any smart people, but smart people we know, like Elon Musk or Bill Gates or these guys are being like, well, we need to have some sort of like International Congress about what we're doing with these particular computer components, because, and these, and these artificial intelligences, because we can make something that we can't control, and it can have far-reaching consequences for us as a species. What is it that's scary about them? And how do we kind of harness this energy and usefulness? And is the inevitable conclusion not that they're going to become scary regardless, because they're going to become so smart? Isn't, in other words, is",
            "start": 1005.0
        },
        {
            "text": "do we kind of harness this energy and usefulness? And is the inevitable conclusion not that they're going to become scary regardless, because they're going to become so smart? Isn't, in other words, is there some sort of like ethical concern that we might not want to go down this road at all, because we can't turn back? I mean, yes, very much so. But I think technology in general has kind of moved us farther away from other social creatures. You know, social media points our faces at a screen instead of at another person. And one of the things that got me really fascinated in robotics when I started with, with it, was that you are interacting with a creature. It is in your physical world, it's in your space. You can look at it, you can see it move. It feels more social to me, it feels more real. I think we, we will create beings that are more capable than us eventually, and we have a responsibility to, to make them ethically. Yes, what is, but what is this specific concern? Like we have these dynamic kind of",
            "start": 1043.56
        },
        {
            "text": "Science Fiction solutions or these kind of, these, these alternate futures of, of, you know, a defense system that runs amok, or in Battlestar Galactica, this group of enslaved robots that turns on everyone, or, you know, whatever. Is that the realistic, like, in other words, why is it always so dire? It seems so dire. Like sci-fi seems to mimic a lot of what we end up having in the future anyway. Like these people are, these are salient points that seem to be things that come to fruition eventually. So why is it our, why is it the conclusion of smart people like yourself and smart people like Bill Gates, Elon Musk, and these guys that just invest lots of money in technology, that the out, the outcome is inevitably going to be nefarious, I guess I should say, because any technology can be used",
            "start": 1092.6
        },
        {
            "text": "Bill Gates, Elon Musk, and these guys that just invest lots of money in technology that the out the outcome is inevitably going to be nefarious, I guess I should say, because any technology can be used positively or negatively. And if we had robots that were perfectly ethical and there was somebody very smart who could subvert that, that um, then it's a huge, huge issue. So I think, I think the fear is more in that if we don't have some way to to control the ethics of a robot or to dictate what is acceptable behavior for a robot or not, um, that people will start doing that without asking, you kind of like a Dr. Wily situation in Mega Man, so near and dear to my heart. So what is happening now within that kind of realm to control it? Like, are there steps being laid? I know that there's been call for, I'm just using the word Congress, like a Continental Congress kind of thing, but a words like an international kind of agreement that these are the steps we're going to take and all the, is that, is, is that",
            "start": 1142.88
        },
        {
            "text": "just using the word Congress, like a Continental Congress kind of thing, but a words like an international kind of agreement that these are the steps we're going to take and all the, is that, is, is that achievable? Is that something that's being pursued actively? Yeah, they have put together sort of a uh, a task force to discuss the ethics of of AI and Robotics as it moves forward, um, but there's no greater framework that's preventing anybody from who innovates from from doing wrong with their technology. And what, like, what, give me a few examples of like what could be wrong? Like, like, like just as it just, and it could be Pie in the Sky, I don't know, but like, is it that far from what we see in sci-fi? No, I mean, even with modern day robots, you know, a drone is is a very powerful tool and you could, you could put a weapon on a drone, you could strap an explosive to a drone and fly it into something and that's a very real modern, like, there's no way to prevent that currently, but it's still a possibility",
            "start": 1207.36
        },
        {
            "text": "put a weapon on a drone, you could strap an explosive to a drone and fly it into something and that's a very real modern, like, there's no way to prevent that currently, but it's still a possibility with the technology that we have. So I think situations like that where we now have these devices that are capable of flying, you know, a 5 mile range and we can strap things to them, that already an ethical concern in my opinion. And so the idea then is that as things get more sophisticated, so too the danger become more sophisticated. Okay, so what is like, what in your mind, you know, we were talking about Kurzweil specifically about, I guess he, he, The Singularity is what 2045 he thought that, and and that's basically when humanity is outpaced, um, does that date seem reasonable to you that the idea that we will, we only have a few more decades until we create something that's smarter than us? I think computers could be doing more advanced science and than humans by 2045, could be innovating more than humans just",
            "start": 1257.6
        },
        {
            "text": "only have a few more decades until we create something that's smarter than us. I think computers could be doing more advanced science and than humans by 2045, could be innovating more than humans just because of their sheer computational power and ability to run more simulations concurrently than a human brain can. And so kind of swinging it to a more positive sense, like what kind of positive things can come out of that development? Like what, like what could, as opposed to the dystopian apocalyptic kind of shit that we focus on because it's interest, like, well, both sides are interesting, but it's, we have a compelling humans, like it's like Book of Revelation, like we have a compelling reason to just keep going back to this dark shit. But what is the positive side of that? Like if assume the ethic, assume the ethics are on the up and up, assume um, roboticist and and AI engineers and software engineers and everyone kind of come together and create something that's that's responsible, what kind of",
            "start": 1315.64
        },
        {
            "text": "assume the ethics are on the up and up, assume um, roboticist and and AI engineers and software engineers and everyone kind of come together and create something that's that's responsible, what kind of great science can come out of this that will help us in 0, 30, 40, 50 years that, you know, is the positive side of it, right? I mean, I think we could, you know, focusing on the science side, um, there're already robots that are kind of doing biology experiments basically, you know, doing the work that a PhD student who is very, very highly trained, um, they basically pipet things all day long, um, and they're just running their experiments, but their brain cycles should be used on other things. A robot or an algorithm, that's what they're made for is to do repetitive tasks. So the more we can make these special purpose functional robots that can do these repeatable tasks in the real world or on our data, um, then the more it frees up human brains to do what human brains are best at doing, which is thinking",
            "start": 1357.56
        },
        {
            "text": "purpose functional robots that can do these repeatable tasks in the real world or on our data, um, then the more it frees up human brains to do what human brains are best at doing, which is thinking outside of the box, being creative, um, coming up with novel solutions, which is where algorithms traditionally fail. And kind of flipping the coin on its head, because we talked a little bit about it, but at the same pace, like what, give me specific examples, not today with the drones and kind of every rudimentary strapping of explosive, what is the dire situation in 50 years if we, if we don't control? Like what, like what do you see happening that could be so detrimental to humanity or to a society? One thing that worries me is that an AI could get so advanced that it could kind of kill the internet, um, or affect the internet so much that Global Commerce, Global Communication came to a halt even for a little bit, and that would just be so tremendously bad, um, and it, it might not even be an an algorithm that",
            "start": 1404.16
        },
        {
            "text": "the internet so much that Global Commerce, Global Communication came to a halt even for a little bit, and that would just be so tremendously bad, um, and it, it might not even be an an algorithm that was intended to do that. I think the the government could get involved in robotics and provide some sort of thing for people to use and they could have nefarious intents behind it. So assume there's now self-driving trains, cars, all provided by a city by the government, um, they could be monitoring you, they could be, um, infringing on your rights, um, and they could be vulnerable to attacks, um, to security exploits from other people, um, or or people who design those robots who have malicious intent. I did read something that Uber was hiring hackers specifically to try to hack their cars and I assume that, um, this is something that they're always going to have to deal with. They're always going have to be one step ahead and it seems like the guys on the other side of the fence that are on the Deep net or",
            "start": 1459.12
        },
        {
            "text": "this is something that they're always going to have to deal with. They're always going have to be one step ahead and it seems like the guys on the other side of the fence that are on the Deep net or whatever the fuck they call it, or these guys that are very smart and sophisticated that don't necessarily work for big companies that I don't want to say use their skills for evil, I don't know if that's really true, but this more like kind of ambiguous agnostic Mr. Robot kind of shit that's going on, right? Like I assume there'll always be one step ahead, right? Like this, this, this probably can't be nipped in the bud. There is going to be a cost of progress. People are going to, and I don't want to make it sound so dire, people are going to die, people are going to get hurt, people are going to get maimed by robots and robotic things and AI or whatever, but absolutely, but presumably these will be learned from and we will be a better society as a result, I assume, right? Presumably, and I, I think",
            "start": 1523.92
        },
        {
            "text": "get maimed by robots and robotic things and AI or whatever, but absolutely, but presumably these will be learned from and we will be a better society as a result, I assume, right? Presumably, and I, I think already there's a need for regulation, you know, self-d self-driving cars, the technology is there, um, the problems right now are people on the streets. So if it was all self-driving cars, we would be so fine, um, it's dealing with people with the uncertainty of humans acting alongside these robots, um, that sometimes makes it kind of a logistical nightmare, um, and that requires governments to become involved, um, you know, if if we could outfit streets with sensors that would, that would help self-driving cars a lot, but the reality is we have built our physical world to not have technology in it and now we're trying to build things like self-driving cars that navigate that world, um, along with other people and that that can create kind of the most complications. It sounds like uh, Kevin, do you remember",
            "start": 1553.28
        },
        {
            "text": "we're trying to build self-driving cars that navigate that world, um, along with other people and that that can create kind of the most complications. It sounds like uh, Kevin, do you remember what that specific website was? Remember when we did The GameOverGreggy Show about the self-driving cars and the decisions they have to make? Do you remember what that was called? Can you find that for me? Yeah, but wasn't that about ethics? Like the people's ethics? Well, it was about, no, it was about the what, what, like what does it, there was this website, I don't, do you know what I'm talking about where it's like the car is going to kill the human, the baby or the human with the old woman, but it has to do one of them, right? And it would ask a lot of people this kind of crowdsource the answer and say this is the ethical answer based on most humans and that, and is it as binary as that? Like, is, I mean, is that how they're going to have to learn? Is is through the experience of humans that seem",
            "start": 1612.84
        },
        {
            "text": "and say this is the ethical answer based on most humans and that, and is it as binary as that? Like, is, I mean, is that how they're going to have to learn? Is is through the experience of humans that seem faulted even at a more an ethical level themselves? In other words, we are ethically infringed humans, all of us that are now trying to make an ethical machine that makes ethical choices and it seems like it's only going to learn from the way we program them, right? But we're trying to build these machines in our image with the with the assumption that we are ethical beings, even though that's not how our behavior often acts out. It's fascinating actually and it's kind of it creates an interesting conundrum. I've talked about in the past, I don't know if it's scientifically sound or not, that it seems like humans have outsmarted evolution in a sense and they're probably the only species that have done it because we obviously dominate the planet. We are outside of our own the Cradle of Life, the our own",
            "start": 1653.28
        },
        {
            "text": "humans have outsmarted evolution in a sense and they're probably the only species that have done it because we obviously dominate the planet. We are outside of our own the Cradle of Life, the our own, you know, the middle of Africa and the Middle East, all these kinds of things have expanded and have greatly affected everything around us. It seems like we are going to now create something, the next step of outsmarting evolution seems to be playing God in a way, which is very fascinating and creates its own not so much ethical but but religious and societal consequences that I think are fun to think and I'm sure there there professionals in your field that deal with only those things similar to bioethics and all that kind of stuff as well, right? What um, this question keeps coming back to my mind and it's a silly question, but it's something our audience can kind of relate to. Do have you watched Westworld? Yeah, okay, so that see the show reminds me what I've seen, we're about halfway through it. How",
            "start": 1698.92
        },
        {
            "text": "it's a silly question, but it's something our audience can kind of relate to. Do have you watched Westworld? Yeah, okay, so that see the show reminds me what I've seen, we're about halfway through it. How far away we away we from something like that? Is that like 100 years away? Is that, and I'm not saying we're going to have a fuck theme park which people go to to fuck, you know, human humanoid robots. What I'm saying is like something that is so sophisticated that it is completely and wildly indistinguishable from anything in that we actually take pleasure, take pleasure in or use it in a commercial way. I think 100 years is a safe bet. We we would probably have something indistinguishable from another um, animal in about a 100 years. It's pretty, it's pretty wild. Does it make you as as a roboticist today, does it make you, I've always wondered this about scientists specifically, like the guys that worked on um, Apollo for instance, although that was a, you know, that was a huge quantum leap, does it make",
            "start": 1738.8
        },
        {
            "text": "does it make you, I've always wondered this about scientists specifically, like the guys that worked on um, Apollo for instance, although that was a, you know, that was a huge quantum leap, does it make you sad that you're you're kind of setting this the the the the the pathway for future roboticists in three or four generations to be able to do the work that you wish you could achieve right the second, but still it is very necessary work. It's like Sir Isaac Newton figuring out that that the apple's falling at a specific trajectory that helps 400 years later a spaceship go to, you know, to space, whatever, um, it's it's frustrating, but it's also exciting because the tools that we build, like the the reason we can do such advanced stuff in robotics and AI today is because of the tools that were built by our forefathers in the in artificial intelligence, by the work they did, by the groundwork they laid, by their failed ideas, by their successful ideas, um, so while it's frustrating that I don't",
            "start": 1786.64
        },
        {
            "text": "by our forefathers in the in artificial intelligence, by the work they did, by the groundwork they laid, by their failed ideas, by their successful ideas, um, so while it's frustrating that I don't think I'm ever going to create a robot that is sentient and an artificial intelligence, um, it still doesn't make the the journey any less exciting for me. You know, it's it's probably such an ignorant thing for me to even put forth, but not being a scientist, not having that education, having a more Humanities driven kind of understanding of everything, it seems to me that I, I just, I don't believe that it won't happen in your lifetime for some reason, specifically because it's, and again, it's a very laying kind of thing, very ignorant kind of thing, but it's like the microprocessor, the leap to, you know, something like uh, these these imageless kind of computers in the mid-70s, the Altair and all these kinds of things too, to Apple I at, you know, at Berkeley, to like, it it wasn't that long ago, you know, and like",
            "start": 1830.44
        },
        {
            "text": "like uh, these these imageless kind of computers in the mid-70s, the Altair and all these kinds of things too, to Apple I at, you know, at Berkeley, to like, it it wasn't that long ago, you know, and like it makes me wonder if if everyone's being a little safe in in their assumptions, not understanding the implications of what you're talking about to nearly the depth you do, but looking back only to, you know, our my my parents are in their mid-60s, they were in their, you know, what mid-20s when the microprocessor was invented and then look at all of the things we have now. And to me it's like, I don't know, like I, like it would be amazing. I, I, I hope you get to build that that device because it doesn't seem that outrageous for someone in their late 20s, early 30s to be 60 and having built something that they didn't expect anymore than when, you know, Steve Jobs was finally crafting Macintosh that they thought that they would have the iPhone at near the end of his life, you know, so there are a few things that",
            "start": 1881.6
        },
        {
            "text": "expect anymore than when, you know, Steve Jobs was finally crafting Macintosh that they thought that they would have the iPhone at near the end of his life, you know, so there are a few things that would have to happen for me to say, okay, I think it's going to happen within our lifetime. One of them is power technology. Batteries, um, have kind of really lagged behind Moore's Law in terms of, you know, doubling every every year, um, batteries are not getting that much better at a crazy rate, um, and we would need robots with a tremendous amount of power to go for a whole day, um, and so, so power technology is one thing. Self repair is another, like I said, um, most robots are meticulously crafted, um, and have to be serviced a decent amount of times, um, and so if some company started working on a robot that could repair itself, um, then I, I might start getting a little more worried about about in our lifetime robots that could potentially um, fix themselves and outsmart humans because outsmarting a human is one",
            "start": 1924.96
        },
        {
            "text": "repair itself, um, then I, I might start getting a little more worried about about in our lifetime robots that could potentially um, fix themselves and outsmart humans because outsmarting a human is one thing, but if you don't have any ability to affect the real world, then it's just all kind of hypothetical, right? Is it, is it, is it a, I know we're jumping around a lot, but I, I'm just asking these questions as they come to me because I've never had someone this smart to pick their brain about this specific thing. Is it a safe assump, like the assumption of a lot of AI and Robotics driven sci-fi that has a more dystopian slant, which is most of it, makes the assumption that humanity will see or robotics or robots or AI will see, will see a system in which humanity is the only imperfect part of it, the one that's stymying it from advancing further? Is that a safe assumption that that AI would come to? In other words, looking at a, you know, because they are mathematically driven and they're looking at this",
            "start": 1987.6
        },
        {
            "text": "that's stymying it from advancing further? Is that a safe assumption that that AI would come to? In other words, looking at a, you know, because they are mathematically driven and they're looking at this very imperfect, right-brained kind of humanity driven philosophical being that they can't really comprehend that's in the way. Is that a safe assumption that that, you know, or is that a logical assumption that an AI would see humans and be like, we want to eradicate you, not because we hate you, but because you are an annoyance to the system working and functioning properly? I think, I think it's a realistic conclusion given that humans are very self-destructive and we're harming the planet where we basically take resources, reproduce too much, um, and I think that maybe if a, if an algorithm realized some fundamental nature about the universe, um, and realized that human beings were detracting in some way from the universe, that's that's why these sci-fi um, writers come to these conclusions is because",
            "start": 2044.72
        },
        {
            "text": "fundamental nature about the universe, um, and realized that human beings were detracting in some way from the universe, that's that's why these sci-fi um, writers come to these conclusions is because ultimately we are doing harm to the world and to ourselves. And if we built a perfect organism that could act like we all want to act, then it might be its logical conclusion that we should get rid of all nonperfect organisms. Yeah, it seems like a scary, but it seems, it seems logical to me, not understanding exactly how the algorithm would work or how an AI would necessarily think that it would look at the imperfect components and try to remove them, um, so it is, it does, it makes sense to me, but I didn't know if a scientist look looks at some of these things and it's like, this is, this doesn't really make any sense at all, it's kind of nonsensical. So it sounds like there's some some, you know, when there's smoke there's fire, it seems like there's some some element of truth to it. I think",
            "start": 2093.8
        },
        {
            "text": "really make any sense at all, it's kind of nonsensical. So it sounds like there's some some, you know, when there's smoke there's fire, it seems like there's some some element of truth to it. I think so. The other thing I want to touch base with you on uh, before we go is um, the idea of um, robotics in AI affecting humans and the way humans are uh, moving forward. In other words, we're talking a lot about robots being crafted from, you know, from clay basically, that they're we're building them from the ground up and we're and we're programming them. Is there a future for Robotics and or AI? And I think it's more probably AI centric, but robotics would play a role in it where we meld with them and some sort of way where it's like we are no longer, you know, we are no longer human in in a in a sense. I think that's a much more realistic uh, short-term future for us that we will augment our bodies, um, that it will be common place to see um, robotically or AI augmented people out on on the street and you",
            "start": 2148.08
        },
        {
            "text": "that's a much more realistic uh, short-term future for us that we will augment our bodies, um, that it will be common place to see um, robotically or AI augmented people out on on the street and you already see that today. Um, Hugh Herr, one of the professors at the MIT Media Lab where I studied, he basically lost his leg in a climbing accident and he wasn't a scientist at the time and he decided he he was a climber, like a full-time climber, and he decided I'm going to spend the rest of my life building robotic limbs because I no longer have a leg. And he's now a better climber because he can have a longer reach with his leg, he can have a smaller foothold. So we're already seeing, you know, real augmentations of people's bodies using robots, um, and I don't expect that to change in the next 0 years. And the more we kind of put the tools for building robots into normal people's hands through the Maker Movement, through things like that, um, I think people will start experimenting with augmenting",
            "start": 2191.12
        },
        {
            "text": "and the more we kind of put the tools for building robots into normal people's hands through the Maker Movement, through things like that, um, I think people will start experimenting with augmenting their own bodies with with gadgets. Is there an equal ethical concern there? Kind of a different one actually, but an equal weighted ethical concern about what people will do to themselves and like the idea of kind of losing your humanity of controlling things that were not meant to be controlled? I think so, but it seems like it's yes, and again, you're giving one person kind of the control over this system. So if this person is malicious, they could do harm with it, um, so it's still kind of all centered around humans making bad decisions, humans who are malicious and want to use technology for bad, that's always going to be around, but it can also do a lot of good. So where do you see that kind of going in the next 10, 0, 30 years in terms of the way it affects and interfaces with us as humans in terms",
            "start": 2246.08
        },
        {
            "text": "always going to be around, but it can also do a lot of good. So where do you see that kind of going in the next 10, 0, 30 years in terms of the way it affects and interfaces with us as humans? In terms of like, could it, could, could a blind person see? Could a, could a deaf person hear? I mean, we already see that with cochlear implants and stuff like that. And I know that that that surgery, uh, eye surgery is getting very sophisticated now in terms of of identifying reasons, uh, repairable reasons people might go blind, um, but is that possible? Is it possible to have a robotic, uh, or a robotic eyeball that somehow interfaces with your brain and your brain doesn't know that it's not your eye? Or I know we already see what people trying to clone organs and do all these kinds of things and I know that there's a lot of different ways a more biological driven way to go about it, but is it not fair to say that a robotic driven way of repairing people's problems is is probably going to be the norm? Yeah, as you",
            "start": 2299.72
        },
        {
            "text": "a lot of different ways a more biological driven way to go about it, but is it not fair to say that a robotic driven way of repairing people's problems is is probably going to be the norm? Yeah, as you said, yeah, definitely. It's interesting to me because I don't know how I feel about it. Like I, like it's, it's, is it going to be, we talked about this a little bit in um, you're you play games, it's a Mass Effect, I'm sure you've played, um, there are all sorts of different species and all sorts of different, you know, gadgets and and whatnot or whatever, but is there not something quaint about the human who's human, you know, who isn't, who is untouched and unscathed as he came from the primordial ooze himself, right? Um, as opposed to, and I don't know how I feel about that, like, do you think that that's kind of um, primitive human rationalization standing in the way of one of the great things that we have, which is progress, like unlimited progress? Well, I think",
            "start": 2339.8
        },
        {
            "text": "to that or you think that that's kind of um primitive human rationalization standing in the way of one of the great things that we have which is progress like unlimited progress well I think we are evolutionarily we we have haven't had to survive for so long as a species um that we haven't advanced as much as a species it's very easy to stay alive as a human now compared to a thousand years ago and you know you think about a thousand years before that and a thousand years before that it is really easy to exist now so I think people are thinking a lot more about how to not just exist as a human but to be better than a human to be faster to be smarter to be stronger and that's where the augmentation is really the motivating factor um is that people have all these extra brain cycles and all this extra time to do whatever they want to do instead of survive um and we want to be better yeah it seems it seems logical and rational to me but there seems to be something very romantic about",
            "start": 2381.44
        },
        {
            "text": "all this extra time to do whatever they want to do instead of survive um and we want to be better yeah it seems it seems logical and rational to me but there seems to be something very romantic about what's being lost as well like we seem to be at some sort of in my personal estimation we've talked about this I think on our on our show before but we seem to be at some sort of generational leap that is very unique in human history and and we can go back to obviously uh Cro-Magnon and Neanderthal and the things the crazy things that were going on in their lives and how they met and the Cro-Magnon were smarter and and but there's a little pieces of Neanderthal in us you know and I wonder if we've come to some sort of place in society where there's going to be a purist movement where there's going to be a movement in 50 years where people don't it reminds me of that that Black Mirror episode I don't know if you watch Black Mirror with the episode of the where they all have those those",
            "start": 2438.44
        },
        {
            "text": "going to be a movement in 50 years where people don't it reminds me of that that Black Mirror episode I don't know if you watch Black Mirror with the episode of the where they all have those those eyes that can rewind and look at things but that one girl doesn't and uh if we're going to look at people like that and think that they're weird or that there's going to be something like kind of pure about it because they didn't succumb to the rash of of technological advancements that add life or utility to our lives well think about somebody who doesn't have a smartphone there are pros and cons to it they are probably much more aware of their physical surroundings much more social um but if you want to send them money good luck um if you want to you know if they want to take a video right away good luck so there are pros and cons to all of these technologies um and I think there will probably be some movement that fights back against this if there's not already you know there are",
            "start": 2482.44
        },
        {
            "text": "away good luck so there are pros and cons to all of these technologies um and I think there will probably be some movement that fights back against this if there's not already you know there are researchers um Sherry Turkle is uh basically a a Harvard psychologist who looks at why technology is taking us farther away from each other um why technology is separating humans and making us more alone um yeah and it is I mean it's true I mean like I feel like you and I and and many of our viewers and the people that work at Kinda Funny and and our and our contemporaries our peers just in that in that in in the age we're at in 2017 I think if you're maybe between 25 and 35 or 40 this unique Nexus uh between uh the way things were and the way things are going to be and that we are the gener the last generation our memory is the way things were right um and that actually lived in that world right and but also advancing forward into a world as the some of the pioneers knowing that we're changing it",
            "start": 2526.08
        },
        {
            "text": "generation our memory is the way things were right um and that actually lived in that world right and but also advancing forward into a world as the some of the pioneers knowing that we're changing it knowing that if I thought about myself when I was seven in 1990 or whatever that none of this was happening like this this was Far G we were playing NES and we had maybe if you were lucky you had a 386 in your house if you were you know if you had some money and you use the phone on the back wall in your kitchen and you and you you didn't know what the hell the internet was cuz it didn't you know it existed but the World Wide Web didn't exist yet and robots were something that you read about in Isaac Asimov novels and it seems like things have advanced so quickly and this spe I think this specific generation is going to be a pivotal one and I don't know if you agree in terms of you know I talked to Adam about it where we were we were talking and I'm like I feel like we're going to tell our",
            "start": 2584.08
        },
        {
            "text": "generation is going to be a pivotal one and I don't know if you agree in terms of you know I talked to Adam about it where we were we were talking and I'm like I feel like we're going to tell our grandkids like we they're going to look at our lives now as so quaint nonetheless the way the lives will be you know the way the lives were pre this where like we had this this thing where we we called someone and they actually a person actually came and picked us up you know five years ago that would have been like unbelievable Greg and I were talking about that where it's like it seems so Uber seems so shady back in the day and then we had person and then in a few years people aren't going to pick us up anymore now car is just going to arrive we're going to get in we're not going to talk or interface with anyone and we're going to get out and they're going to look at that particular moment is so quaint because they're like you called a person that drove a car and I don't know it's I love I",
            "start": 2624.16
        },
        {
            "text": "with anyone and we're going to get out and they're going to look at that particular moment is so quaint because they're like you called a person that drove a car and I don't know it's I love I love thinking about that kind of stuff and I really do feel like this and maybe it's just the my mom always said like it's like every generation thinks they're the most important and every generation thinks they're seeing the end and I'm like but I just do feel like there's something about this you know about like this age and I mean I think there is there you know printers I think printers will be completely foreign to our kids um printing out digital information on a piece of physical paper like MapQuest do you remember having to print out a map and put it in your car and like you had to plan you now do not have to plan because of technology everything happens for you so I think a lot of the while future generations might look back and think it's quaint I think the the danger is in that they",
            "start": 2658.6
        },
        {
            "text": "now do not have to plan because of technology everything happens for you so I think a lot of the while future generations might look back and think it's quaint I think the the danger is in that they are not going to be thinking for themselves um because everything will be so easy yeah and that is scary and maybe that is an evolutionary challenge that we have to confront as well that things become yeah too easy and then normal everyday or or even catastrophic events will become more harder to overcome as as we succumb more and not necessarily to group think I don't think but just group think in the sense that we would rely on AI or rely on computers rely on the internet MapQuest is a great example because in the late 90s yeah in the early 2000s you would print out you go to a concert I remember going to a concert at Jones Beach on Long Island my friend we printed out directions to they were totally fucking wrong but we printed them out we got lost and all that kind of stuff and then Garmin and",
            "start": 2702.72
        },
        {
            "text": "to a concert at Jones Beach on Long Island my friend we printed out directions to they were totally fucking wrong but we printed them out we got lost and all that kind of stuff and then Garmin and all these guys started being like oh you can have a GPS in your car and they built them in the cars and now like no one uses GPS and now you have a phone right and that's the same reason why I think that like we collectively as a society are understanding how just how fucking quick we advance like we are accelerating not advancing but accelerating which why I'm confident and I'm hopeful that you get to build like the the whatever dream has been in your mind since you're a kid I hope that you get to to build it because I just I just feel like all the evidence even though smart people like yourself are like well we have all these major hurdles to overcome the more Layman guy like me is but but but I'm like but look around you you know like I just don't I just can't this flat screen TV is worth",
            "start": 2747.92
        },
        {
            "text": "are like well we have all these major hurdles to overcome the more Layman guy like me is but but but I'm like but look around you you know like I just don't I just can't this flat screen TV is worth almost nothing that we're looking at for our conference monitor right now 10 years ago yeah that would have cost $3,000 you know it's true and it would have been 720p and it would have been terrible and it would have been thick Mm-hmm CRTs are going to be these things that no one even remember so I I I I I I'm excited about the future because I I'm interested in it whether it goes bad or not I actually don't even know if I care because I just want to see what what happens it'll be different it'll be different it'll be exciting uh the last thing I wanted to ask you I know I said that a while ago but one thing that came to mind for me and I don't know if you can speak to this but this is something that's interesting to me as well is the digitization of the human experience of the mind of memories",
            "start": 2784.2
        },
        {
            "text": "one thing that came to mind for me and I don't know if you can speak to this but this is something that's interesting to me as well is the digitization of the human experience of the mind of memories is this something that's possible and is this something that's going to to to to come to fruition in terms of helping AI advance more or in terms of embodying a robot with the actual human or the idea of never dying and all these kinds of things that people talk about in very kind of American you know American Scientific Frontiers kind of ways where it's like are these things happening can someone plug something into me one day and and see what I'm thinking can they plug something into me and see what my memories are is a way is that digitized in a way that a is the brain digitized in a way that a computer can understand or is that something that they're trying to work on interfacing we still don't know that um but I think digitizing information is a very interesting um application where",
            "start": 2826.0
        },
        {
            "text": "a computer can understand or is that something that they're trying to work on interfacing we still don't know that um but I think digitizing information is a very interesting um application where robotics in AI is super relevant right now I mean imagine if you just had a bunch of cameras in your home and they recorded everything and you could search them by keywords or by date and you could resolve any argument that happened in your home by getting a ground truth that was the actual interaction that happened you know that would be a technology that could both be negative and positive you could have a memory like a a physical memory of everything a a video of opening presents on Christmas morning um it might not be from your perspective but it would be a record of it um and I think that type of kind of everywhere like cameras and microphones everywhere that will happen in our lifetime you know everything is going to be recorded in our lifetime so it's a similar ubiquity that you were",
            "start": 2864.16
        },
        {
            "text": "of kind of everywhere like cameras and microphones everywhere that will happen in our lifetime you know everything is going to be recorded in our lifetime so it's a similar ubiquity that you were talking about with uh with data driven internet driven kind of things for AI the same kind of observing human interaction or human activity human interaction right instrumented, just being recorded optically and audibly as yeah and in terms of interfacing with the brain that's just still such a we still don't really know much about the brain um which is fascinating because you were saying that in order to make a a fully-fledged AI which might be one of the things one of the hurdles you were talking about is is that we need to replicate every part of the brain and it seems like very little is understood about it well that that is one assumption that kind of classical founders of artificial intelligence took a very biologically inspired approach is that you know we need to know how humans think and emulate that but",
            "start": 2916.96
        },
        {
            "text": "that that is one assumption that kind of classical founders of artificial intelligence took a very biologically inspired approach is that you know we need to know how humans think and emulate that but actually the biggest advancements in AI in the past 10 years are nothing to do with how humans think um even though they're called neural nets and they're kind of inspired by the way a brain has neurons um they are very very carefully crafted by humans um instead of grown and and kind of instead of um learning from experience while they do do that there's a lot of bootstrapping that has to happen and that happens in the brain too we just don't know how it happens so even if we knew how the brain learned um we might not know what the assumptions were that that would allow for that learning so there's kind of a a a chicken and egg problem that we both need to know how the brain learns and grows over time but we need to know what is hardcoded to what is you know what what comes when you're",
            "start": 2959.6
        },
        {
            "text": "there's kind of a a a chicken and egg problem that we both need to know how the brain learns and grows over time but we need to know what is hardcoded to what is you know what what comes when you're born I wonder if this might be a super ignorant thing to say but also like the more primitive nature of the brain in terms of like the brain stem the breathing that the like the things that we we don't even know how we control or we don't think about we know how how it happens but that that might not even really need to like we don't in other words we don't need to replicate the entire brain because there's just things in the brain that an AI wouldn't need or a robot wouldn't need anyway and so maybe it makes more sense for the human to craft it right in the image that in in which it it it it fulfills the functions that it was designed to fulfill right without having to worry about this primitive stuff that comes from right and and that's why robotics is so functional now is because",
            "start": 3019.16
        },
        {
            "text": "it fulfills the functions that it was designed to fulfill right without having to worry about this primitive stuff that comes from right and and that's why robotics is so functional now is because people say um you know I want to build this general purpose AI and huge failure but you say I want to build a robot that cleans the floor and 10 years of hard work will get you there um and so very application specific very you know a thing that needs to be solved that's easy to do but to create a thing that can solve all things that's kind of what I don't think is going to happen within our lifetime because that is fundamentally what makes humans special cool we'll leave it there I think that I think this was fascinating I was super interesting and super uh thought-provoking and I hope it provoked thought for you guys out there as well um you know I like that nerdy stuff I know a lot of you guys like that stuff as well and Adam's perfect for that so we appreciate you coming thank you so",
            "start": 3061.88
        },
        {
            "text": "thought for you guys out there as well um you know I like that nerdy stuff I know a lot of you guys like that stuff as well and Adam's perfect for that so we appreciate you coming thank you so much thanks for having me Colin uh and remember well if you're watching this or listening to this you already subscribed to us on Patreon um but you know uh I hope you enjoyed it I want to do more things like this in the future so uh give us your feedback Keep It Coming uh hope you guys are doing well Happy New Year since this is the first episode uh of the New Year and uh we'll see you next time thank you",
            "start": 3107.64
        }
    ]
}